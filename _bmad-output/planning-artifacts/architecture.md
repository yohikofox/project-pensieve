---
stepsCompleted: [1, 2, 3, 4, 5]
inputDocuments:
  - _bmad-output/planning-artifacts/product-brief-pensine-2026-01-09.md
  - _bmad-output/planning-artifacts/prd.md
  - _bmad-output/planning-artifacts/ux-design-specification.md
  - docs/liquid-glass/site.md
workflowType: 'architecture'
project_name: 'pensine'
user_name: 'yohikofox'
date: '2026-01-12'
lastUpdated: '2026-01-13'
---

# Architecture Decision Document - Pensine

_Ce document se construit de mani√®re collaborative √† travers une d√©couverte √©tape par √©tape. Les sections s'ajoutent au fur et √† mesure que nous travaillons ensemble sur chaque d√©cision architecturale._

**Author:** yohikofox
**Date:** 2026-01-12
**Project:** Pensine - Incubateur Personnel d'Id√©es Business

---

## Project Context Analysis

### Requirements Overview

**Functional Requirements (31 FRs identifi√©es):**

Le syst√®me doit supporter un workflow complet de gestion d'id√©es :

**Capture Multi-Modale (FR1-FR5):**
- Audio 1-tap depuis √©cran principal
- Texte rapide pour contextes publics
- Capture offline compl√®te avec stockage en attente de sync
- Annulation possible en cours d'enregistrement

**Transcription Locale (FR6-FR8):**
- Traitement automatique post-capture via Whisper on-device
- Ex√©cution 100% locale (pas de d√©pendance r√©seau)
- Consultation de la transcription compl√®te par l'utilisateur

**Digestion IA Enrichie (FR9-FR13):**
- G√©n√©ration automatique de r√©sum√©s concis
- Extraction d'id√©es cl√©s
- Support texte et audio
- Notifications de progression pour processus longs

**Todo-List & Actions (FR14-FR20):**
- D√©tection automatique d'actions lors de la digestion
- Extraction de : description, deadline sugg√©r√©e, priorit√©
- Affichage inline dans le Feed par id√©e
- Tab Actions centralis√© avec filtres (Toutes/√Ä faire/Faites)
- Marquage completion + navigation vers id√©e d'origine

**Consultation (FR21-FR24):**
- Liste chronologique des captures
- Vue d√©tail riche (audio, transcription, r√©sum√©, id√©es, todos)
- Consultation offline compl√®te
- Distinction visuelle des captures en attente de digestion

**Synchronisation (FR29-FR31):**
- Sync automatique au retour r√©seau
- Bidirectionnelle (local ‚Üî cloud)
- Informations de statut pour l'utilisateur

**Gestion Compte (FR25-FR28):**
- Cr√©ation compte, login/logout
- R√©cup√©ration mot de passe oubli√©

**Non-Functional Requirements (16 NFRs identifi√©es):**

**Performance (NFR1-NFR5):**
- Capture audio : < 500ms apr√®s tap
- Transcription Whisper : < 2x dur√©e audio
- Digestion IA : < 30s pour capture standard
- Chargement liste : < 1s (cache local)
- Latence per√ßue : feedback visuel obligatoire, jamais d'attente

**Reliability (NFR6-NFR9):**
- **Critique** : 0 capture perdue, jamais (tol√©rance z√©ro)
- Disponibilit√© capture offline : 100%
- R√©cup√©ration apr√®s crash automatique
- Sync automatique sans intervention utilisateur

**Security (NFR10-NFR14):**
- Authentification obligatoire
- HTTPS/TLS pour toutes communications API
- Chiffrement au repos (device + cloud)
- Isolation stricte des donn√©es utilisateur
- Conformit√© RGPD (acc√®s, rectification, suppression)

**Scalability (NFR15-NFR16):**
- Architecture pr√™te pour 100+ utilisateurs sans refonte
- Pas de limite artificielle de stockage MVP

**UX-Driven Architecture Requirements:**

L'UX Spec r√©v√®le des contraintes architecturales fortes :

- **"1-Tap Liberation"** : Latence capture < 1s impose architecture r√©active
- **Offline-first radical** : Toutes les features core doivent fonctionner sans r√©seau
- **Liquid Glass Design System** : Animations fluides, feedback haptique, transitions complexes
- **D√©tection concordance √† chaud** : Traitement temps r√©el post-capture
- **Notifications intelligentes** : Queue de progression pour process IA longs
- **M√©taphore "Jardin d'id√©es"** : Interface contemplative avec visualisation de maturit√©

### Scale & Complexity

**Project Scale Assessment:**

- **Primary domain:** Mobile-first Full-Stack SaaS (React Native + Backend)
- **Complexity level:** Medium
  - MVP focalis√© mais techniquement riche
  - ML on-device (Whisper)
  - Architecture distribu√©e mobile-cloud
  - Offline-first avec sync bidirectionnelle
  - Contraintes performance strictes

- **Estimated architectural components:** 8-12 composants majeurs
  - Mobile app (React Native)
  - Transcription engine (Whisper on-device)
  - Local storage layer (SQLite/WatermelonDB)
  - Sync engine (bidirectional)
  - Backend API
  - AI digestion service
  - Authentication service
  - Todo extraction service
  - Concordance detection engine
  - Queue management (offline tasks)
  - Notification service
  - Storage management (audio retention)

**Complexity Indicators:**

- ‚úÖ **Real-time features:** D√©tection concordance √† chaud post-capture
- ‚è≥ **Multi-tenancy:** Mono-utilisateur MVP, pr√©voir abstraction "owner" pour future √©volution
- ‚ùå **Regulatory compliance:** RGPD requis, pas d'autres contraintes r√©glementaires
- ‚ö†Ô∏è **Integration complexity:** ML on-device (Whisper), AI cloud (GPT), potentiellement OAuth tiers
- ‚úÖ **User interaction complexity:** Haute - capture gestuelle, animations fluides, feedback haptique
- ‚ö†Ô∏è **Data complexity:** Medium - Audio brut + transcriptions + m√©tadonn√©es + relations (concordances, todos)

### Technical Constraints & Dependencies

**Mandatory Technical Constraints:**

1. **Offline-First Radical**
   - 100% des features core fonctionnent sans r√©seau
   - Transcription locale obligatoire (Whisper on-device)
   - Cache local complet pour consultation
   - Queue persistante pour sync et digestion diff√©r√©e

2. **Confidentialit√© Audio**
   - Aucune donn√©e audio ne transite par des tiers non contr√¥l√©s
   - Transcription exclusivement on-device
   - Chiffrement obligatoire (transit + repos)

3. **Performance Mobile**
   - Capture < 500ms
   - Transcription < 2x dur√©e audio (Whisper optimis√©)
   - App install√©e < 100 Mo (sans mod√®le)
   - Mod√®le Whisper ~500 Mo (t√©l√©charg√© post-install)

4. **Cross-Platform Mobile**
   - iOS 15+ et Android 10+ (API 29)
   - React Native pour d√©veloppement partag√©
   - APIs natives pour permissions (micro, storage, notifications)

5. **Fiabilit√© Absolue**
   - Aucune perte de donn√©es, tol√©rance z√©ro
   - Auto-save permanent
   - R√©cup√©ration apr√®s crash

**Known Dependencies:**

- **Whisper (OpenAI)** : Mod√®le ML pour transcription locale
- **React Native** : Framework mobile cross-platform
- **SQLite / WatermelonDB** : Base locale offline-first
- **Backend √† d√©finir** : Node.js/Fastify pressenti (du brainstorming)
- **LLM Cloud** : GPT-4o-mini pressenti pour digestion IA
- **PostgreSQL** : Base backend pressenti (du brainstorming)

### Cross-Cutting Concerns Identified

**1. Offline-First Architecture**
- Impact : Tous les composants
- D√©cision requise : Pattern de sync, r√©solution conflits, queue management

**2. ML On-Device (Whisper)**
- Impact : Performance mobile, taille app, UX transcription
- D√©cision requise : Optimisation mod√®le, fallback si √©chec, gestion m√©moire

**3. Security & Privacy**
- Impact : Tous les composants manipulant donn√©es sensibles
- D√©cision requise : Chiffrement, isolation, conformit√© RGPD

**4. Sync & Conflict Resolution**
- Impact : Mobile ‚Üî Backend
- D√©cision requise : Strat√©gie sync (optimistic/pessimistic), r√©solution conflits

**5. Queue Management**
- Impact : Digestion IA, Sync, Transcription retry
- D√©cision requise : Persistence queue, retry logic, prioritization

**6. Performance & Latency**
- Impact : UX capture, transcription, consultation
- D√©cision requise : Optimisations sp√©cifiques, caching strategy, lazy loading

**7. Storage Management**
- Impact : Audio local, transcriptions, cache
- D√©cision requise : R√©tention audio, cleanup automatique, quotas utilisateur

**8. Notification System**
- Impact : Progression IA, concordances, engagement
- D√©cision requise : Push vs local, timing, opt-in/out

---

## Architectural Style & Strategic Design

### Decision: Domain-Driven Design (Strat√©gique + Tactique)

**Rationale:**
- Domaine m√©tier complexe avec logique riche (concordance, germination, extraction IA)
- Deux domaines parall√®les identifi√©s : GTD/Action vs Opportunity/Germination
- Besoin de s√©paration claire entre contextes pour √©viter couplage
- Architecture pr√©par√©e pour Event Sourcing futur (pas MVP)
- CQRS non n√©cessaire pour MVP (peut √™tre ajout√© si divergence lecture/√©criture)

**Cons√©quences:**
- Communication entre Bounded Contexts via Domain Events (asynchrone)
- Ubiquitous Language distinct par contexte
- Aggregates avec fronti√®res transactionnelles claires
- Event Storming utilis√© pour identifier les contextes

---

## Technology Stack Decisions

### Mobile Stack

**Framework:** React Native avec Expo (custom dev client)
- **Rationale:** Cross-platform iOS/Android, exp√©rience utilisateur existante
- **Custom dev client:** N√©cessaire pour module natif Whisper

**Local Database:** WatermelonDB
- **Rationale:** Offline-first avec sync protocol built-in, observation r√©active
- **Alternative rejet√©e:** Realm (sync abandonn√©), SQLite seul (pas de sync int√©gr√©)

**Transcription:** Whisper.rn ou module custom
- **Rationale:** Transcription 100% locale (confidentialit√©), pas de d√©pendance r√©seau
- **Contrainte:** Mod√®le ~500 Mo t√©l√©charg√© post-install

**Language:** TypeScript strict

---

### Backend Stack

**Framework:** NestJS (TypeScript)
- **Rationale:** Architecture modulaire, connaissance utilisateur, adapt√© DDD
- **Alternative rejet√©e:** Fastify (moins d'exp√©rience, complexit√© DDD √† g√©rer)

**Database:** PostgreSQL
- **Rationale:** Persistence donn√©es relationnelles, ACID, maturit√©

**Message Broker:** RabbitMQ
- **Rationale d√©cisive:**
  - √âlimination Redis SPOF (isolation pannes entre queue et cache)
  - Durabilit√© disk-based > Redis memory-only
  - Exp√©rience utilisateur existante
  - Plugin delayed message exchange fonctionne bien
- **Alternative rejet√©e:** BullMQ (d√©pendance Redis = SPOF)

**Cache:** Redis (cache UNIQUEMENT, pas de queue)
- **Rationale:** Cache session, cache application, s√©par√© de la queue

**Scheduler:** NestJS Schedule (cron jobs)
- **Rationale:** Publie vers RabbitMQ pour traitement asynchrone

**LLM:** GPT-4o-mini (pressenti)
- **Rationale:** Digestion IA (summary, tags, extraction todos/ideas)

---

### Infrastructure

**Dev/Staging:** Docker Compose selfhosted (homelab)

**Production future:** Scaleway ou AWS managed services
- **Rationale:** Migration quand customers arrivent, co√ªt optimis√©

---

## Domain-Driven Design - Strategic Design

### Event Storming - D√©couverte du Domaine

**Approche:** Event Storming Option A (full event storming avant bounded contexts)

**R√©v√©lations Majeures:**

#### 1. Deux Domaines M√©tier Parall√®les (CRITIQUE)

**Flow A : GTD / Action (court, op√©rationnel)**
- Capture ‚Üí Transcription ‚Üí Digestion ‚Üí **Todos extraites**
- Workflow: `EXTRACTED` ‚Üí `LAUNCHED` ‚Üí `IN_PROGRESS` ‚Üí `COMPLETED`
- M√©trique: Task completed
- Ubiquitous Language: "T√¢che", "Action", "Rappel", "√Ä faire"
- Exemple: "Pense √† envoyer facture Mme Micheaux"

**Flow B : Opportunity Incubation (long, strat√©gique)**
- Capture ‚Üí Transcription ‚Üí Digestion ‚Üí **Ideas extraites**
- Workflow: `Idea` ‚Üí `Concordance` ‚Üí `Pattern` ‚Üí `Germination` ‚Üí `Crystallization`
- M√©trique: Idea launched
- Ubiquitous Language: "Id√©e", "Opportunit√©", "Pattern", "Germination", "Concordance", "Project"
- Exemple: "Pain point compta freelance (3√®me mention)"

**‚ùå Erreur √©vit√©e:** Les todos ne se transforment JAMAIS en id√©es germ√©es. Ce sont deux domaines s√©par√©s.

---

#### 2. Cardinalit√© 1-to-Many (CRITIQUE)

**Une SEULE capture** (audio 30s √† plusieurs minutes) peut contenir:
- Plusieurs todos (0-N actions op√©rationnelles)
- Plusieurs id√©es (0-N insights strat√©giques)
- Du contexte m√©lang√©

**Exemple concret:**
```
Capture audio (2 min):
"Faut que je pense √† envoyer la facture √† Mme Micheaux avant vendredi.
J'ai encore crois√© un freelance qui gal√®re avec sa compta, c'est le 3√®me ce mois-ci.
Il y a clairement un truc √† faire l√†-dessus.
Faudrait que je creuse Pennylane et Indy.
Ah et acheter du lait en rentrant."

‚Üí Extraction:
  Todos (3):
    - Envoyer facture Mme Micheaux (deadline: vendredi)
    - Analyser Pennylane et Indy
    - Acheter lait

  Ideas (2):
    - Pain point compta freelance (r√©currence)
    - App compta simplifi√©e ind√©pendants
```

**Hi√©rarchie:**
```
1 Capture (parent)
  ‚îú‚îÄ‚îÄ 0-N Todos (children)
  ‚îú‚îÄ‚îÄ 0-N Ideas (children)
  ‚îú‚îÄ‚îÄ 1 Summary
  ‚îî‚îÄ‚îÄ 0-N Tags
```

---

#### 3. Concept de "Project" (MVP Core)

**D√©finition:** Mat√©rialisation d'une concordance entre plusieurs Ideas.

**Deux chemins de cr√©ation:**

**A. Bottom-Up (√âmergent) - MVP**
```
1. User fait plusieurs Captures (orphelines)
2. Digestion extrait Ideas
3. Concordance Engine d√©tecte pattern
4. ProjectSuggested event
5. User accepte ‚Üí ProjectAccepted
6. Project cr√©√©, Ideas li√©es automatiquement
```

**B. Top-Down (Intentionnel) - Post-MVP**
```
User cr√©e intentionnellement un Project vide
User fait des Captures dans ce Project
Enrichissement intentionnel du contexte
```

**Relations:**
- `Project ‚Üî Ideas`: Many-to-Many
- `Project ‚Üî Captures`: Many-to-Many
- Une Idea peut appartenir √† plusieurs Projects
- Une Capture peut √™tre orpheline ou li√©e √† un/plusieurs Projects

---

#### 4. Capture Polymorphe (Strategy Pattern)

**Types de Capture:**
- Audio (Whisper transcription)
- Texte (d√©j√† normalis√©)
- Image (OCR ou Vision LLM)
- URL (Web scraper)

**D√©cision:** Un seul Aggregate `Capture` polymorphe avec `type` discriminant.

**Rationale:**
- M√™me cycle de vie m√©tier : "capturer une pens√©e pour la dig√©rer"
- Diff√©rence = transformation technique (Strategy Pattern)
- Ubiquitous Language : on parle de "Capture", pas de 4 concepts

**Cons√©quence:** Le "Transcription Context" devient "Normalization Context" (plus g√©n√©rique).

---

### Bounded Contexts Identifi√©s

#### üî• Core Domain (Diff√©renciateurs Business)

**1. Knowledge Context**
- **Responsabilit√©:** Digestion IA et extraction de sens
- **Ubiquitous Language:** Thought, Digestion, Summary, Tags, Extraction
- **Aggregates:** `Thought`
- **Valeur m√©tier:** Transformer le flux de pens√©e brut en insights structur√©s

**2. Opportunity Context**
- **Responsabilit√©:** D√©tection patterns, concordance, germination d'opportunit√©s business
- **Ubiquitous Language:** Idea, Project, Concordance, Pattern, Germination, Maturity, BusinessCase
- **Aggregates:** `Idea`, `Project`
- **Valeur m√©tier:** Incubateur personnel d'id√©es business (le c≈ìur de Pensine)

---

#### üîß Supporting Domain (N√©cessaires mais non diff√©renciateurs)

**3. Capture Context**
- **Responsabilit√©:** Capture multi-modale (audio, texte, image, URL)
- **Ubiquitous Language:** Capture, Recording, Snapshot
- **Aggregates:** `Capture`

**4. Normalization Context**
- **Responsabilit√©:** Normalisation des captures en texte exploitable
- **Ubiquitous Language:** Transcription, OCR, TextExtraction, WebScraping
- **Aggregates:** Aucun (Domain Services stateless)

**5. Action Context**
- **Responsabilit√©:** Gestion cycle de vie des actions (GTD)
- **Ubiquitous Language:** Todo, Task, Action, Deadline, Priority, Completion
- **Aggregates:** `Todo`

---

#### ‚öôÔ∏è Generic Subdomain (G√©n√©riques)

**6. Identity Context**
- **Responsabilit√©:** Authentification, gestion utilisateurs
- **Aggregates:** `User`

**7. Notification Context**
- **Responsabilit√©:** Notifications push et alertes
- **Aggregates:** `Notification`

---

#### üèóÔ∏è Infrastructure (Non-m√©tier)

**8. Sync (Infrastructure)**
- **Responsabilit√©:** Synchronisation offline-first
- **Impl√©mentation:** WatermelonDB + backend sync endpoint
- **Note:** Pas de Bounded Context m√©tier, infrastructure pure

---

### Aggregates & Domain Model

#### Core Aggregates

**1. Capture (Supporting - Capture Context)**
```typescript
Capture {
  id: UUID
  type: 'audio' | 'text' | 'image' | 'url'
  state: 'captured' | 'processing' | 'ready' | 'failed'
  projectId?: UUID  // Peut √™tre null (orpheline)
  rawContent: AudioFile | string | ImageFile | URL
  normalizedText?: string
  capturedAt: DateTime
  location?: GeoPoint
  tags?: string[]
}
```

**2. Thought (Core - Knowledge Context)**
```typescript
Thought {
  id: UUID
  captureId: UUID
  summary: string
  tags: string[]
  extractedTodoIds: UUID[]
  extractedIdeaIds: UUID[]
  digestedAt: DateTime
}
```

**3. Todo (Supporting - Action Context)**
```typescript
Todo {
  id: UUID
  thoughtId: UUID
  state: 'extracted' | 'launched' | 'in_progress' | 'completed' | 'abandoned'
  description: string
  deadline?: DateTime
  priority?: 'low' | 'medium' | 'high'
}
```

**4. Idea (Core - Opportunity Context)**
```typescript
Idea {
  id: UUID
  thoughtId: UUID
  projectIds: UUID[]  // Many-to-Many
  state: 'extracted' | 'warm' | 'germinated'
  description: string
  context?: string
  concordanceScore?: number
}
```

**5. Project (Core - Opportunity Context)**
```typescript
Project {
  id: UUID
  name: string  // Auto-g√©n√©r√© par IA
  origin: 'suggested'  // MVP = toujours suggested (top-down post-MVP)
  state: 'suggested' | 'accepted' | 'germinating' | 'crystallized' | 'rejected'

  // Relations Many-to-Many
  ideaIds: UUID[]
  captureIds: UUID[]

  // Germination
  maturityScore: number
  businessCase?: BusinessCase

  createdAt: DateTime
}
```

---

### Context Map (Relations)

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                    CORE DOMAIN                               ‚îÇ
‚îÇ                                                              ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê         ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê   ‚îÇ
‚îÇ  ‚îÇ   Knowledge      ‚îÇ         ‚îÇ    Opportunity          ‚îÇ   ‚îÇ
‚îÇ  ‚îÇ   Context        ‚îÇ‚óÑ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÇ    Context              ‚îÇ   ‚îÇ
‚îÇ  ‚îÇ                  ‚îÇ         ‚îÇ                         ‚îÇ   ‚îÇ
‚îÇ  ‚îÇ - Thought        ‚îÇ         ‚îÇ - Idea                  ‚îÇ   ‚îÇ
‚îÇ  ‚îÇ - Digestion      ‚îÇ         ‚îÇ - Project               ‚îÇ   ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò         ‚îÇ - Concordance           ‚îÇ   ‚îÇ
‚îÇ         ‚ñ≤                     ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò   ‚îÇ
‚îÇ         ‚îÇ                              ‚ñ≤                    ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
          ‚îÇ                              ‚îÇ
          ‚îÇ ThoughtDigested              ‚îÇ IdeasExtracted
          ‚îÇ                              ‚îÇ
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ         ‚îÇ        SUPPORTING            ‚îÇ                     ‚îÇ
‚îÇ         ‚îÇ                              ‚îÇ                     ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê      ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îê                ‚îÇ
‚îÇ  ‚îÇ   Capture    ‚îÇ      ‚îÇ     Action         ‚îÇ                ‚îÇ
‚îÇ  ‚îÇ   Context    ‚îÇ      ‚îÇ     Context        ‚îÇ                ‚îÇ
‚îÇ  ‚îÇ              ‚îÇ      ‚îÇ                    ‚îÇ                ‚îÇ
‚îÇ  ‚îÇ - Capture    ‚îÇ      ‚îÇ - Todo             ‚îÇ                ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò      ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò                ‚îÇ
‚îÇ         ‚îÇ                                                    ‚îÇ
‚îÇ         ‚îÇ CaptureReady                                       ‚îÇ
‚îÇ         ‚ñº                                                    ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê                                            ‚îÇ
‚îÇ  ‚îÇNormalization ‚îÇ                                            ‚îÇ
‚îÇ  ‚îÇ  Context     ‚îÇ                                            ‚îÇ
‚îÇ  ‚îÇ  (Services)  ‚îÇ                                            ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò                                            ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò

‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                    GENERIC                                  ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê         ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê             ‚îÇ
‚îÇ  ‚îÇ  Identity    ‚îÇ         ‚îÇ  Notification    ‚îÇ             ‚îÇ
‚îÇ  ‚îÇ  Context     ‚îÇ         ‚îÇ  Context         ‚îÇ             ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò         ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò             ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

**Upstream/Downstream Relations:**

| Upstream (U) | Downstream (D) | Communication |
|--------------|----------------|---------------|
| Capture | Knowledge | `CaptureReady` event |
| Knowledge | Action | `TodosExtracted` event |
| Knowledge | Opportunity | `IdeasExtracted` event |
| Opportunity | Capture | `CaptureLinkedToProject` (user capture dans project) |
| Opportunity | Notification | `ProjectSuggested` ‚Üí notification |
| Knowledge | Notification | `ThoughtDigested` ‚Üí notification |

**Anti-Corruption Layers (ACL):**
- **Non n√©cessaires pour MVP** (contextes internes, ubiquitous language clair)
- **√Ä pr√©voir pour int√©grations externes futures** (Notion, Trello, API publique)

---

### Domain Events (MVP)

**Capture Phase:**
- `ThoughtCaptured`
- `NormalizationStarted`
- `CaptureReady`
- `NormalizationFailed`

**Digestion Phase:**
- `DigestionRequested`
- `DigestionStarted`
- `ThoughtDigested`
- `TodosExtracted` (0-N todos)
- `IdeasExtracted` (0-N ideas)
- `DigestionFailed`

**Project Phase (Concordance):**
- `ConcordanceDetectionRequested`
- `ConcordanceDetected`
- `PatternRecognized`
- `ProjectSuggested`
- `ProjectAccepted`
- `ProjectRejected`
- `IdeaAddedToProject`
- `CaptureLinkedToProject`

**Action Phase (Todo Lifecycle):**
- `TodoCreated`
- `TodoLaunched`
- `TodoStarted`
- `TodoCompleted`
- `TodoAbandoned`
- `TodoPostponed`
- `TodoPriorityChanged`

**Sync Phase (Infrastructure):**
- `LocalChangeDetected`
- `SyncRequested`
- `ChangesPushed`
- `ChangesPulled`
- `ConflictDetected`
- `ConflictResolved`
- `SyncCompleted`

**User/Session Phase:**
- `UserRegistered`
- `UserLoggedIn`
- `UserLoggedOut`
- `SessionExpired`

**Notification Phase:**
- `NotificationScheduled`
- `NotificationSent`
- `NotificationDelivered`
- `NotificationFailed`

---

### Policies (R√©actions Automatiques)

**Policy 1: Auto-Normalization**
```
WHEN ThoughtCaptured
THEN StartNormalization
```

**Policy 2: Auto-Digestion**
```
WHEN CaptureReady
THEN RequestDigestion
```

**Policy 3: Auto-Extract Todos**
```
WHEN ThoughtDigested
THEN CreateTodos (pour chaque todo dans digest.todos[])
```

**Policy 4: Auto-Extract Ideas**
```
WHEN ThoughtDigested
THEN CreateIdeas (pour chaque idea dans digest.ideas[])
```

**Policy 5: Auto-Detect Concordance**
```
WHEN IdeasExtracted
THEN DetectConcordance
(peut √™tre async/batched, pas imm√©diat)
```

**Policy 6: Auto-Suggest Project**
```
WHEN ConcordanceDetected
AND concordanceScore > threshold
THEN SuggestProject
```

**Policy 7: Auto-Link Ideas to Project**
```
WHEN ProjectAccepted
THEN AddIdeaToProject (pour chaque idea dans concordance)
```

**Policy 8: Auto-Sync on Network Return**
```
WHEN NetworkAvailable
AND hasPendingChanges
THEN RequestSync
```

**Policy 9: Notify Digestion Complete**
```
WHEN ThoughtDigested
THEN ScheduleNotification("Votre capture a √©t√© dig√©r√©e")
```

**Policy 10: Notify Project Suggested**
```
WHEN ProjectSuggested
THEN ScheduleNotification("Nouveau pattern d√©tect√© : {projectName}")
```

---

## Architectural Decisions Record

### ADR-001: Aggregate Granularity - Aggregates S√©par√©s

**Status:** ‚úÖ ACCEPT√â

**Context:** D√©cider si les phases (Capture, Thought, Idea, Project) sont un seul aggregate ou plusieurs.

**Decision:** Aggregates s√©par√©s avec communication via Domain Events.

**Rationale:**
- `Capture` ‚Üí cycle de vie distinct (normalisation peut √©chouer ind√©pendamment)
- `Thought` ‚Üí cycle de vie distinct (digestion compl√®te m√™me si rien n'est extrait)
- `Idea` ‚Üí cycle de vie long (concordance, germination sur plusieurs semaines/mois)
- `Project` ‚Üí cycle de vie long et distinct (agr√®ge plusieurs Ideas)
- Fronti√®res transactionnelles naturelles

**Cons√©quences:**
- Loose coupling entre phases
- Communication asynchrone via Domain Events
- R√©silience : √©chec d'une phase n'impacte pas les autres

---

### ADR-002: Normalization - Domain Service (pas Aggregate)

**Status:** ‚úÖ ACCEPT√â

**Context:** La normalisation (Whisper, OCR, web scraper) doit-elle √™tre un Aggregate ou un Service ?

**Decision:** Domain Services stateless, pas d'Aggregate `Normalization`.

**Rationale:**
- Transformation technique transitoire
- √âtat m√©tier pertinent reste dans `Capture.state`
- Tra√ßabilit√© via logs applicatifs suffisante pour MVP
- Pas de business logic complexe dans la normalisation elle-m√™me

**Cons√©quences:**
- Simplicit√© : pas d'aggregate suppl√©mentaire
- Pas de double √©tat (Capture + Normalization)
- Si besoin analytics plus tard ‚Üí ajouter `NormalizationAttempt` comme Value Object

---

### ADR-003: Sync - Infrastructure (pas Bounded Context)

**Status:** ‚úÖ ACCEPT√â

**Context:** Le sync offline-first est-il un contexte m√©tier ou de l'infrastructure ?

**Decision:** Infrastructure pure, pas de Bounded Context m√©tier.

**Rationale:**
- WatermelonDB g√®re d√©j√† le sync protocol
- Pattern g√©n√©rique offline-first (pas sp√©cifique √† Pensine)
- R√©solution conflits simple (last-write-wins ou timestamp)
- Pas de logique m√©tier Pensine dans le sync

**Cons√©quences:**
- Sync = infrastructure technique
- Domain Events doivent √™tre syncables (transports par le sync)
- Pas de SyncContext dans le mod√®le m√©tier

---

### ADR-004: Digestion IA - Un seul appel LLM

**Status:** ‚úÖ ACCEPT√â

**Context:** L'extraction (summary, tags, todos, ideas) doit-elle se faire en un ou plusieurs appels LLM ?

**Decision:** Un seul appel LLM structur√©.

```typescript
const digest = await llm.digest(transcription, {
  extract: ['summary', 'tags', 'todos', 'ideas']
});
```

**Rationale:**
- Co√ªt LLM r√©duit (1 appel vs 3)
- Latence r√©duite (pas d'attente s√©quentielle)
- LLM voit contexte global pour extraction coh√©rente
- Prompt engineering moderne permet multi-extraction structur√©e

**Cons√©quences:**
- Prompt complexe (mais g√©rable avec structured output)
- Si LLM √©choue ‚Üí tout √©choue (mais retry possible)
- Frugalit√© : co√ªt optimis√© pour MVP

---

### ADR-005: Capture Vide - Stock√©e

**Status:** ‚úÖ ACCEPT√â

**Context:** Que faire d'une Capture sans todo ni idea extraite ? (ex: "Il fait beau")

**Decision:** Stock√©e quand m√™me, user d√©cide de la conserver ou supprimer.

**Rationale:**
- Principe NFR6 : "0 capture perdue, jamais"
- Contexte futur potentiel (pens√©e spontan√©e peut devenir pertinente plus tard)
- Stockage texte minime (quelques octets)
- User autonomie : UI peut filtrer "Avec actions/id√©es uniquement"

**Cons√©quences:**
- Historique complet pr√©serv√©
- Capture reste transcrite et r√©sum√©e (avec tags potentiels)
- UI doit permettre filtrage pour ne pas polluer le feed

---

### ADR-006: Association Manuelle Capture ‚Üî Todo - Post-MVP

**Status:** ‚úÖ ACCEPT√â (Post-MVP)

**Context:** User peut-il lier manuellement une Capture √† une Todo existante apr√®s coup ?

**Decision:** Pas MVP, mais architecture pr√©vue via tags communs.

**Use case post-MVP:**
- Todo extraite : "Investiguer solutions compta"
- Plus tard, user capture : "Article int√©ressant sur pain points compta"
- Tags communs d√©tect√©s ‚Üí suggestion de lien

**Rationale:**
- Complexit√© UX non prioritaire pour MVP
- Tags g√©n√©r√©s par IA permettront d'impl√©menter cette fonctionnalit√© facilement plus tard
- Architecture events-based permet d'ajouter `TodoLinkedToCapture` event en V1.5

**Cons√©quences:**
- MVP : pas d'association manuelle
- Post-MVP : via tags ou UI explicite
- Event `TodoLinkedToCapture` pr√©vu dans l'architecture

---

## V1.5 Features (Post-MVP)

**Enrichissement Post-Capture:**
- User peut ajouter audio/texte suppl√©mentaire √† une Capture existante
- Re-digestion automatique avec contexte enrichi
- Events: `EnrichmentRequested`, `ThoughtEnriched`, `ReDigestionTriggered`

**Brainstorm Guid√©:**
- IA pose questions pour creuser une Idea/Project
- G√©n√©ration Business Case structur√©
- Events: `BrainstormSessionStarted`, `ConceptCrystallized`, `BusinessCaseGenerated`

**Partage Filtr√©:**
- User partage une Idea/Project (digest anonymis√©)
- Collaboration invitation
- Events: `IdeaSharedRequested`, `ShareLinkCreated`, `CollaborationAccepted`

**Cr√©ation Manuelle de Project (Top-Down):**
- User cr√©e intentionnellement un Project vide
- Captures dans ce Project enrichissent contexte
- Command: `CreateProject` (manuel, pas suggested)

---

## Starter Template Decision

### ADR-007: From Scratch Approach (pas de starter full-stack)

**Status:** ‚úÖ ACCEPT√â

**Context:** Choisir entre utiliser des starters/boilerplates existants vs partir des CLI officiels.

**Starters √âvalu√©s:**

**Mobile:**
- [Obytes Starter](https://starter.obytes.com/) : Expo + TypeScript + MMKV + React Query + TailwindCSS
- [Fast Expo App](https://github.com/Teczer/fast-expo-app) : CLI avec Expo SDK 54 + MMKV + React Query

**Backend:**
- [NestJS Clean Architecture Boilerplate](https://github.com/rezawr/nestjs-clean-architecture-boilerplate) : DDD + Clean Architecture
- [NestJS-DDD-DevOps](https://andrea-acampora.github.io/nestjs-ddd-devops/) : DDD Modular Monolith + DevOps

**Decision:** Partir de z√©ro avec CLI officiels, copier uniquement configs/tooling.

**Rationale:**

**1. Architecture DDD Sp√©cifique D√©j√† D√©finie**
- 8 Bounded Contexts identifi√©s via Event Storming
- Structure par contexte m√©tier unique √† Pensine
- Les starters imposent leur structure g√©n√©rique (user/product/order)
- Refonte compl√®te n√©cessaire = perte de temps

**2. Stack Technique Particuli√®re**
- Whisper.rn (module custom, pas dans les starters)
- WatermelonDB (peu de starters l'int√®grent bien)
- Liquid Glass Design System (custom, pas TailwindCSS g√©n√©rique)
- RabbitMQ (rare dans starters NestJS)
- Aucun starter ne match cette stack exactement

**3. Suring√©nierie des Starters**
- Patterns "enterprise-grade" over-engineered (multi-tenancy, microservices ready)
- MVP mono-user = simplicit√© prioritaire
- Abstractions complexes √† comprendre et maintenir
- D√©pendances impos√©es difficiles √† remplacer

**4. Temps R√©el**
```
Starter full-stack:
- Setup: 2h
- Comprendre: 3h
- Nettoyer inutile: 5h
- Adapter architecture: 8h
- Debug conflicts: 3h
TOTAL: 21h

From Scratch:
- CLI official: 1h
- Tooling: 2h
- Structure DDD custom: 4h
- Int√©grations: 6h
- Tests: 3h
TOTAL: 16h

Gain net: 5h + contr√¥le total
```

**5. Projet Solo**
- Pas besoin conventions d'√©quipe impos√©es
- Flexibilit√© pour ajuster rapidement
- Code ma√Ætris√© √† 100%

**Decision D√©taill√©e:**

**Mobile:**
```bash
# Partir de Expo CLI officiel
npx create-expo-app@latest pensine-mobile --template blank-typescript

# Copier configs de Obytes (tooling uniquement):
- tsconfig.json strict
- .eslintrc minimal
- jest.config.js
- GitHub Actions EAS Build workflow
```

**Backend:**
```bash
# Partir de NestJS CLI officiel
npx @nestjs/cli new pensine-backend

# Structure DDD custom bas√©e sur Event Storming:
src/
  contexts/
    knowledge/      (Core Domain)
      domain/
      application/
      infrastructure/
    opportunity/    (Core Domain)
    capture/        (Supporting)
    action/         (Supporting)
    normalization/  (Supporting)
  shared/
```

**Ce Qui Sera R√©utilis√© des Starters:**
- ‚úÖ Config files (tsconfig, eslint, jest)
- ‚úÖ Scripts package.json (lint, test, format)
- ‚úÖ GitHub Actions workflows (CI/CD basiques)
- ‚úÖ Documentation patterns (README structure)
- ‚ùå Code m√©tier (100% custom)

**Cons√©quences:**
- Setup initial l√©g√®rement plus long (1-2h)
- Contr√¥le total sur architecture et d√©pendances
- Code parfaitement align√© avec Event Storming
- Pas de dette technique d√®s le d√©part
- Ma√Ætrise compl√®te du codebase

**R√©f√©rences:**
- [Obytes Starter](https://starter.obytes.com/)
- [Fast Expo App](https://github.com/Teczer/fast-expo-app)
- [NestJS Clean Architecture Boilerplate](https://github.com/rezawr/nestjs-clean-architecture-boilerplate)
- [Awesome NestJS Boilerplates](https://awesome-nestjs.com/resources/boilerplate.html)

---

### ADR-008: Anti-Corruption Layer (ACL) √† la Fronti√®re Mobile/Backend

**Status:** ‚úÖ ACCEPT√â

**Context:** D√©terminer o√π les ACL sont n√©cessaires dans l'architecture Pensine.

**Decision:** ACL obligatoire √† la fronti√®re mobile ‚Üî backend (API Sync Layer), mais pas entre bounded contexts backend.

**Rationale:**

**Pas d'ACL entre Bounded Contexts Backend (Internes):**
- Contextes m√©tier internes avec contr√¥le total
- Ubiquitous language coh√©rent et partag√©
- Communication via Domain Events bien d√©finis
- Aucun risque de corruption de mod√®le

**ACL OBLIGATOIRE √† la fronti√®re Mobile ‚Üî Backend:**

La structure des donn√©es mobile et backend PEUT diverger volontairement:

```typescript
// MOBILE (WatermelonDB - structure d√©normalis√©e pour performance)
@model('captures')
class Capture {
  @field('type') type: string
  @field('raw_content') rawContent: string  // JSON stringifi√©
  @field('normalized_text') normalizedText: string
  @field('tags') tags: string  // JSON array stringifi√©
  @json('metadata', (json) => json) metadata: any
}

// BACKEND (DDD - structure normalis√©e)
class Capture {
  id: UUID
  type: CaptureType  // Value Object
  rawContent: AudioFile | TextContent | ImageFile  // Union type
  normalizedText?: NormalizedText  // Value Object
  tags: Tag[]  // Collection de Value Objects
  metadata: CaptureMetadata  // Value Object structur√©
}
```

**L'API Sync Layer joue le r√¥le d'ACL et DOIT:**

**1. VALIDATION (Protection Domaine)**
```typescript
// Rejeter donn√©es invalides avant qu'elles n'atteignent le domaine
POST /sync/push
{
  changes: {
    captures: {
      created: [{
        id: "...",
        type: "audio",
        raw_content: "invalid_json"  // ‚ùå REJET√â par ACL
      }]
    }
  }
}
‚Üí 400 Bad Request (domaine backend jamais pollu√©)
```

**2. TRANSFORMATION (Structure Mobile ‚Üî Backend)**
```typescript
// Mobile ‚Üí Backend (Pull response)
{
  raw_content: '{"audioUri": "file://..."}',  // JSON string
  tags: '["business", "idea"]'                 // JSON array string
}

// ACL transforme vers structure backend:
{
  rawContent: new AudioFile(uri),              // Value Object
  tags: [new Tag("business"), new Tag("idea")] // Collection VOs
}

// Backend ‚Üí Mobile (Push)
{
  rawContent: audioFile.toJSON(),
  tags: tags.map(t => t.value)
}
‚Üí Mobile re√ßoit format d√©normalis√© attendu
```

**3. TRADUCTION VOCABULARY**
```typescript
// Mobile utilise vocabulaire technique:
raw_content, normalized_text, audio_file_path

// Backend utilise vocabulaire m√©tier:
rawContent, normalizedText, audioFile

// ACL traduit bidirectionnellement
```

**Avantages de cette approche:**

- **Mobile optimis√©:** Structure plate, JSON strings pour performance, moins de joins
- **Backend prot√©g√©:** Validation stricte, types forts, Value Objects
- **Flexibilit√©:** Changer structure mobile sans impacter backend (et vice-versa)
- **√âvolution ind√©pendante:** Mobile et backend peuvent √©voluer √† des rythmes diff√©rents

**Cons√©quences:**
- API Sync doit impl√©menter transformations bidirectionnelles
- Tests d'int√©gration critiques pour valider ACL
- Documentation des mappings mobile ‚Üî backend obligatoire
- Co√ªt CPU l√©ger pour transformations (acceptable pour MVP)

---

### ADR-009: Strat√©gie de Synchronisation Mobile ‚Üî Backend

**Status:** ‚úÖ ACCEPT√â

**Context:** D√©finir comment la synchronisation offline-first fonctionne entre mobile et backend.

**Decision:** 6 d√©cisions valid√©es pour la strat√©gie de sync compl√®te.

---

#### 9.1 - Timing de Synchronisation

**Decision:** Option C - Balanced (launch + post-action + polling 15min)

**Triggers de sync:**
1. **Au lancement app** (priorit√© haute)
2. **Apr√®s actions critiques** (capture, digestion completed, todo completed)
3. **Polling background 15min** (si app ouverte)
4. **Retour r√©seau** (apr√®s p√©riode offline)

**Rationale:**
- Balance entre r√©activit√© et consommation batterie
- Donn√©es critiques (captures) synchronis√©es rapidement
- Polling 15min raisonnable pour updates non-critiques
- Pas de sync agressive permanente

**Impl√©mentation:**
```typescript
// 1. Au lancement
useEffect(() => {
  syncService.sync({ priority: 'high' });
}, []);

// 2. Apr√®s action critique
onCaptureComplete(() => {
  syncService.sync({ priority: 'high', entity: 'captures' });
});

// 3. Polling background
setInterval(() => {
  if (appState === 'active') {
    syncService.sync({ priority: 'low' });
  }
}, 15 * 60 * 1000);

// 4. Retour r√©seau
NetInfo.addEventListener(state => {
  if (state.isConnected) {
    syncService.sync({ priority: 'medium' });
  }
});
```

---

#### 9.2 - D√©tection et R√©solution de Conflits

**Decision:** Utiliser le m√©canisme standard de WatermelonDB avec `lastPulledAt` + `last_modified` per-record.

**Comment √ßa fonctionne:**

```typescript
// 1. PULL PHASE (Backend ‚Üí Mobile)
GET /sync/pull?last_pulled_at=2026-01-13T09:00:00Z

Backend retourne:
{
  changes: {
    captures: {
      updated: [
        { id: "c1", last_modified: 1736759400000, ... }  // Modifi√© apr√®s lastPulledAt
      ]
    }
  },
  timestamp: 1736760600000  // Nouveau lastPulledAt pour le client
}

Mobile enregistre: lastPulledAt = 1736760600000

// 2. PUSH PHASE (Mobile ‚Üí Backend)
POST /sync/push
{
  last_pulled_at: 1736760600000,
  changes: {
    captures: {
      updated: [
        { id: "c1", ... }
      ]
    }
  }
}

Backend v√©rifie pour CHAQUE record:
IF server.last_modified > request.last_pulled_at
THEN ‚Üí CONFLIT (donn√©e modifi√©e c√¥t√© serveur depuis dernier pull)
ELSE ‚Üí OK (accepter push)
```

**R√©solution des conflits d√©tect√©s:**

```typescript
// Strat√©gie per-column client-wins avec logique m√©tier
class SyncConflictResolver {
  resolve(serverRecord, clientRecord, entity) {
    switch(entity) {
      case 'capture':
        // M√©tadonn√©es techniques: serveur gagne
        return {
          ...clientRecord,
          normalized_text: serverRecord.normalized_text,  // Serveur
          state: serverRecord.state,                      // Serveur

          // Donn√©es user: client gagne
          tags: clientRecord.tags,                        // Client
          projectId: clientRecord.projectId               // Client
        };

      case 'todo':
        // √âtat m√©tier: client gagne (user a agi localement)
        return {
          ...serverRecord,
          state: clientRecord.state,                      // Client
          completed_at: clientRecord.completed_at,        // Client

          // M√©tadonn√©es: serveur gagne
          priority: serverRecord.priority                 // Serveur (calcul√© par IA)
        };

      default:
        return clientRecord;  // Client-wins par d√©faut
    }
  }
}
```

**Gestion multi-clients:**

Chaque client a son propre `lastPulledAt`, le syst√®me fonctionne correctement:

```
Timeline:
10:00 - Record cr√©√© (last_modified = 10:00)
10:15 - MobileA pull (lastPulledAt_A = 10:15)
10:30 - MobileB pull (lastPulledAt_B = 10:30)
10:31 - MobileA modifie + push
        ‚Üí Backend: last_modified = 10:31
10:32 - MobileB modifie + push
        ‚Üí Backend d√©tecte: server.last_modified (10:31) > client.lastPulledAt_B (10:30)
        ‚Üí CONFLIT correctement d√©tect√©
```

**Support backoffice & API externes:**

```typescript
// Modification directe en DB (backoffice, cron job, API externe)
UPDATE captures SET normalized_text = '...', last_modified = NOW();

// Prochain pull mobile d√©tecte automatiquement:
GET /sync/pull?last_pulled_at=2026-01-13T10:00:00Z
‚Üí Backend retourne record avec last_modified > lastPulledAt
‚Üí Mobile applique update correctement
```

**Rationale:**
- M√©canisme √©prouv√© de WatermelonDB
- `lastPulledAt` client-specific permet multi-clients
- `last_modified` server-side source de v√©rit√©
- Fonctionne avec backoffice et modifications externes
- Per-column resolution permet business logic fine

---

#### 9.3 - Gestion des Fichiers (Audio)

**Decision:** Option C - Upload Queue s√©par√©e

**Architecture:**

```typescript
// 1. Capture audio sauvegard√©e localement imm√©diatement
const capture = await captureService.create({
  type: 'audio',
  audioUri: 'file://local/audio123.m4a',  // Local file
  state: 'captured'
});

// 2. Ajout √† upload queue
await uploadQueue.enqueue({
  captureId: capture.id,
  fileUri: capture.audioUri,
  priority: 'high'
});

// 3. Upload asynchrone ind√©pendant du sync
uploadQueue.process({
  onSuccess: (captureId, remoteUrl) => {
    // Update capture avec URL remote
    db.captures.update(captureId, {
      audioRemoteUrl: remoteUrl,
      uploadState: 'completed'
    });
  },
  onError: (captureId, error) => {
    // Retry avec backoff
    uploadQueue.retry(captureId, { delay: fibonacci(attemptCount) });
  }
});

// 4. Sync metadata s√©par√©ment (pas bloqu√© par upload)
syncService.sync();  // Sync capture metadata m√™me si upload en cours
```

**Retry Upload Strategy:**

```typescript
class UploadQueue {
  async retry(item, options) {
    const delays = [1, 1, 2, 3, 5, 8, 13, 21, 34, 55]; // Fibonacci en secondes
    const maxDelay = 5 * 60;  // Cap √† 5 minutes

    const delay = Math.min(
      delays[item.attemptCount] * 1000,
      maxDelay * 1000
    );

    await sleep(delay);
    return this.upload(item);
  }
}
```

**Rationale:**
- Upload fichiers lents/volumineux ne bloque pas sync metadata
- Retry ind√©pendant avec backoff
- Capture utilisable imm√©diatement (fichier local)
- Transcription Whisper fonctionne sur fichier local
- Upload asynchrone en arri√®re-plan

**Cons√©quences:**
- Complexit√© l√©g√®rement augment√©e (2 syst√®mes)
- Gestion √©tats: `pending`, `uploading`, `completed`, `failed`
- Cleanup fichiers locaux apr√®s upload r√©ussi

---

#### 9.4 - Priorit√© de Synchronisation

**Decision:** Option B - Priority-based (Captures > Todos > Ideas > Projects)

**Ordre de sync:**

```typescript
const SYNC_PRIORITY = {
  captures: 1,     // HIGHEST - donn√©es critiques user
  todos: 2,        // HIGH - actions utilisateur
  thoughts: 3,     // MEDIUM - r√©sultats digestion
  ideas: 4,        // LOW - concordances peuvent attendre
  projects: 5      // LOWEST - suggestions peuvent attendre
};

async function sync() {
  const entities = Object.keys(SYNC_PRIORITY)
    .sort((a, b) => SYNC_PRIORITY[a] - SYNC_PRIORITY[b]);

  for (const entity of entities) {
    await syncEntity(entity);
  }
}
```

**Sync incr√©mental si timeout:**

```typescript
// Si connexion lente ou timeout, sync par batch prioritaires
async function syncWithTimeout(timeoutMs = 10000) {
  const startTime = Date.now();

  for (const entity of prioritizedEntities) {
    if (Date.now() - startTime > timeoutMs) {
      console.log(`Timeout: synced up to ${entity}`);
      break;  // Reste sera synced au prochain trigger
    }

    await syncEntity(entity);
  }
}
```

**Rationale:**
- Captures = donn√©es critiques (NFR6: "0 capture perdue")
- Todos = actions user importantes
- Ideas/Projects = peuvent attendre (non-bloquant)
- Connexion lente ou timeout ne perd pas donn√©es critiques

---

#### 9.5 - Retry Logic & Error Handling

**Decision:** Result Pattern + Fibonacci Backoff (cap 5min)

**Result Pattern (pas try/catch):**

```typescript
// Enum de r√©sultats
enum SyncResult {
  SUCCESS = 'success',
  NETWORK_ERROR = 'network_error',
  AUTH_ERROR = 'auth_error',
  CONFLICT = 'conflict',
  SERVER_ERROR = 'server_error',
  TIMEOUT = 'timeout'
}

type SyncResponse = {
  result: SyncResult;
  data?: any;
  error?: string;
  retryable: boolean;
};

// Usage
const response = await syncService.sync();

switch (response.result) {
  case SyncResult.SUCCESS:
    showToast('Sync r√©ussie');
    break;

  case SyncResult.NETWORK_ERROR:
    if (response.retryable) {
      scheduleRetry({ delay: fibonacci(attemptCount) });
    }
    break;

  case SyncResult.AUTH_ERROR:
    redirectToLogin();  // Non retryable
    break;

  case SyncResult.CONFLICT:
    resolveConflict(response.data);
    break;
}
```

**Fibonacci Backoff:**

```typescript
const fibonacciDelays = [1, 1, 2, 3, 5, 8, 13, 21, 34, 55];  // Secondes
const maxDelay = 5 * 60;  // Cap 5 minutes

function getRetryDelay(attemptCount: number): number {
  const fibDelay = fibonacciDelays[Math.min(attemptCount, fibonacciDelays.length - 1)];
  return Math.min(fibDelay, maxDelay) * 1000;  // En millisecondes
}

// Exemple timeline:
// Attempt 1: 1s
// Attempt 2: 1s
// Attempt 3: 2s
// Attempt 4: 3s
// Attempt 5: 5s
// Attempt 6: 8s
// Attempt 7: 13s
// Attempt 8: 21s
// Attempt 9: 34s
// Attempt 10: 55s
// Attempt 11+: 5min (capped)
```

**Rationale (Fibonacci > Exponential):**

```
Fibonacci: 1, 1, 2, 3, 5, 8, 13, 21, 34, 55 ‚Üí 5min cap
Exponential (base 2): 2, 4, 8, 16, 32, 64, 128, 256 ‚Üí trop agressif

Avantages Fibonacci:
- Bagottage r√©seau temporaire: r√©cup√©ration rapide (1s, 1s, 2s)
- Backend down prolong√©: monte progressivement sans exploser
- 5min cap √©vite attente infinie
- Soulage backend lors recovery (pas de stampede avec exponential)
```

**Rationale Result Pattern > try/catch:**
- Code appelant peut interpr√©ter enum facilement
- Switch exhaustif (TypeScript v√©rifie tous les cas)
- Retry logic centralis√©e et claire
- Pas de exceptions non catch√©es qui crashent l'app

---

#### 9.6 - Schema Versioning

**Decision:** Simple versioning (pas de Schema Registry pour MVP)

**Approche:**

```typescript
// Mobile envoie version de schema dans headers
POST /sync/push
Headers:
  X-Schema-Version: 1.0.0

// Backend valide compatibilit√©
if (requestSchemaVersion !== serverSchemaVersion) {
  if (isCompatible(requestSchemaVersion, serverSchemaVersion)) {
    // OK - backward compatible
    applyMigration(requestSchemaVersion);
  } else {
    // KO - force app update
    return { error: 'APP_UPDATE_REQUIRED' };
  }
}
```

**Migration strategy:**

```typescript
// Changement de sch√©ma (ex: ajout colonne)
// V1.0.0 ‚Üí V1.1.0

// Backend supporte les 2 versions:
function handlePush(data, schemaVersion) {
  switch (schemaVersion) {
    case '1.0.0':
      // Ancienne version - remplir nouvelle colonne avec default
      return {
        ...data,
        newColumn: 'default_value'
      };

    case '1.1.0':
      // Nouvelle version - utiliser directement
      return data;
  }
}
```

**Rationale:**
- MVP mono-user: pas besoin Schema Registry complexe
- Header version suffit pour validation
- Backend peut supporter N-1 versions facilement
- Force update si breaking change critique
- Post-MVP: migrer vers Schema Registry si multi-versions critiques

**Cons√©quences:**
- Simple √† impl√©menter
- Backend doit g√©rer migrations manuellement
- Documentation versions obligatoire
- Si scaling: ajouter Schema Registry (Kafka Schema Registry, etc.)

---

**Cons√©quences globales ADR-009:**
- Sync robuste et performante
- 0 perte de donn√©es garantie
- Multi-clients support√© nativement
- Backoffice compatible
- Code maintenable avec Result Pattern

---

### ADR-010: Security & Encryption Strategy

**Status:** ‚úÖ ACCEPT√â

**Context:** D√©finir la strat√©gie de s√©curit√© et de chiffrement pour prot√©ger les donn√©es sensibles des utilisateurs (audio, transcriptions, id√©es business).

**Decision:** 5 d√©cisions valid√©es pour la s√©curit√© compl√®te du syst√®me.

---

#### 10.1 - Strat√©gie d'Authentification

**Decision:** JWT Access Token (courte dur√©e) + Refresh Token (longue dur√©e)

**Architecture:**

```typescript
// 1. Login
POST /auth/login
{
  email: "user@example.com",
  password: "***"
}

Response:
{
  accessToken: "eyJhbGc...",      // JWT 15min
  refreshToken: "rt_abc123...",   // 30 jours
  expiresIn: 900                  // 15min en secondes
}

// 2. Access Token stock√© en m√©moire (React state)
// 3. Refresh Token stock√© en Keychain/Keystore (s√©curis√©)

// 4. Refresh automatique avant expiration
GET /auth/refresh
Headers:
  Authorization: Bearer rt_abc123...

Response:
{
  accessToken: "eyJhbGc...",      // Nouveau JWT 15min
  expiresIn: 900
}

// 5. R√©vocation (logout, compromission)
POST /auth/revoke
Headers:
  Authorization: Bearer rt_abc123...

‚Üí Refresh token supprim√© de DB (blacklist)
```

**Caract√©ristiques:**

**Access Token (JWT):**
- Dur√©e: **15 minutes**
- Stockage: **M√©moire** (React state, pas AsyncStorage)
- Format: JWT sign√© (HS256 ou RS256)
- Claims: `{ sub: userId, email, iat, exp }`
- Stateless: backend ne stocke pas (v√©rifie signature)

**Refresh Token:**
- Dur√©e: **30 jours**
- Stockage: **Keychain (iOS) / Keystore (Android)** (chiffr√© OS)
- Format: Random string opaque (UUID v4)
- Stateful: stock√© en DB backend avec metadata
- R√©vocable: peut √™tre invalid√© c√¥t√© serveur

**Rationale:**
- Access token court (15min) limite window d'exploitation si vol√©
- Refresh token long (30 jours) √©vite re-login fr√©quent
- Stockage s√©par√©: access en m√©moire (volatil), refresh s√©curis√© OS
- R√©vocation: logout ou compromission invalide refresh token
- Balance s√©curit√©/UX optimale pour mobile

**Rotation Refresh Token (Post-MVP):**
```typescript
// Chaque refresh g√©n√®re nouveau refresh token (rotation)
POST /auth/refresh
‚Üí Ancien refresh token invalid√©
‚Üí Nouveau refresh token √©mis
‚Üí Protection contre vol de refresh token
```

---

#### 10.2 - Chiffrement au Repos (Mobile)

**Decision:** MVP = Keychain/Keystore pour tokens, Post-MVP = SQLCipher pour DB compl√®te

**MVP (Minimal Viable Security):**

```typescript
// Tokens sensibles chiffr√©s par OS
import * as SecureStore from 'expo-secure-store';

// Stockage refresh token
await SecureStore.setItemAsync('refresh_token', refreshToken);

// R√©cup√©ration
const refreshToken = await SecureStore.getItemAsync('refresh_token');

// Suppression (logout)
await SecureStore.deleteItemAsync('refresh_token');
```

**Donn√©es stock√©es en Keychain/Keystore (MVP):**
- ‚úÖ Refresh Token (critique)
- ‚úÖ User credentials si "Remember me" (optionnel)
- ‚ùå DB WatermelonDB: **non chiffr√©e** (SQLite standard)

**Rationale MVP:**
- Keychain/Keystore = chiffrement hardware-backed (Secure Enclave iOS, TEE Android)
- Protection tokens critique sans overhead performance
- DB non chiffr√©e acceptable pour MVP mono-user
- Transcriptions/ideas pas r√©glement√©es (pas HIPAA/donn√©es sant√©)

**Post-MVP (Production Hardening):**

```typescript
// SQLCipher pour chiffrement DB compl√®te
import { Database } from '@nozbe/watermelondb';
import SQLiteAdapter from '@nozbe/watermelondb/adapters/sqlite';

const adapter = new SQLiteAdapter({
  dbName: 'pensine',
  // SQLCipher encryption
  encryptionKey: await getEncryptionKey()  // D√©riv√©e du Keychain
});

const database = new Database({
  adapter,
  modelClasses: [Capture, Thought, Todo, Idea, Project]
});
```

**Cl√© chiffrement DB:**
- G√©n√©r√©e au premier lancement (crypto.randomBytes(32))
- Stock√©e dans Keychain/Keystore
- DB inaccessible sans d√©verrouillage device
- Performance impact: ~15% overhead (acceptable)

**Rationale Post-MVP:**
- Protection compl√®te donn√©es sensibles (transcriptions, id√©es business)
- Conformit√© certifications (si B2B futur)
- Pas d'impact UX (transparent)

---

#### 10.3 - Chiffrement au Repos (Backend)

**Decision:** MVP = Disk/Volume Encryption (Infrastructure), Post-MVP = TDE ou Column-level si r√©gul√©

**MVP (Infrastructure-level Encryption):**

```bash
# Docker Volume chiffr√© (LUKS)
docker volume create \
  --driver local \
  --opt type=none \
  --opt device=/encrypted/data \
  --opt o=bind \
  pensine-data

# PostgreSQL stock√© sur volume chiffr√©
services:
  postgres:
    volumes:
      - pensine-data:/var/lib/postgresql/data

# Scaleway/AWS: Volumes chiffr√©s par d√©faut
# - AWS EBS: encryption at rest (AES-256)
# - Scaleway Block Storage: LUKS encryption
```

**Rationale MVP:**
- Chiffrement volume = protection vol physique disques
- Transparent pour application (pas de code)
- Gratuit sur cloud providers modernes
- Conforme exigences basiques s√©curit√©

**Post-MVP (Database-level Encryption):**

**Option A: Transparent Data Encryption (TDE)** (PostgreSQL 15+)
```sql
-- Chiffrement automatique toutes les tables
ALTER DATABASE pensine SET encryption = 'on';
```

**Option B: Column-level Encryption** (donn√©es ultra-sensibles)
```typescript
// Chiffrement s√©lectif colonnes sensibles
class Capture {
  id: UUID;

  @Encrypted()  // Chiffr√© avec cl√© backend
  normalizedText: string;

  @Encrypted()
  rawContent: string;

  state: string;  // Non chiffr√© (ok)
}
```

**Quand utiliser Post-MVP:**
- R√©gulations sp√©cifiques (HIPAA, PCI-DSS)
- Clients B2B exigeants (compliance)
- Multi-tenancy avec isolation forte
- Audit trail chiffr√© (tra√ßabilit√©)

**Rationale:**
- MVP: infrastructure encryption suffit
- Post-MVP: database encryption si besoin m√©tier
- √âviter sur-engineering pr√©matur√©
- Performance impact TDE: ~10%, Column: ~20%

---

#### 10.4 - Communication S√©curis√©e (TLS/HTTPS)

**Decision:** TLS 1.3 obligatoire, certificats Let's Encrypt, HSTS activ√©

**Configuration Backend:**

```typescript
// NestJS HTTPS configuration
import * as https from 'https';
import * as fs from 'fs';

const httpsOptions = {
  key: fs.readFileSync('/certs/privkey.pem'),
  cert: fs.readFileSync('/certs/fullchain.pem'),
  // TLS 1.3 minimum
  minVersion: 'TLSv1.3',
  // Ciphers modernes uniquement
  ciphers: [
    'TLS_AES_128_GCM_SHA256',
    'TLS_AES_256_GCM_SHA384',
    'TLS_CHACHA20_POLY1305_SHA256'
  ].join(':')
};

const app = await NestFactory.create(AppModule, {
  httpsOptions
});
```

**Headers S√©curit√©:**

```typescript
// Helmet.js (security headers)
app.use(helmet({
  hsts: {
    maxAge: 31536000,        // 1 an
    includeSubDomains: true,
    preload: true
  },
  contentSecurityPolicy: {
    directives: {
      defaultSrc: ["'self'"],
      scriptSrc: ["'self'"],
      styleSrc: ["'self'", "'unsafe-inline'"],
      imgSrc: ["'self'", "data:", "https:"],
      connectSrc: ["'self'", "https://api.pensine.example.local"]
    }
  }
}));
```

**Mobile (Certificate Pinning - Post-MVP):**

```typescript
// Expo config.json
{
  "expo": {
    "ios": {
      "infoPlist": {
        "NSAppTransportSecurity": {
          "NSExceptionDomains": {
            "api.pensine.example.local": {
              "NSIncludesSubdomains": true,
              "NSExceptionRequiresForwardSecrecy": true,
              "NSExceptionMinimumTLSVersion": "TLSv1.3",
              "NSPinnedDomains": [
                "api.pensine.example.local"
              ]
            }
          }
        }
      }
    }
  }
}
```

**Rationale:**
- TLS 1.3: protection MITM, forward secrecy
- Let's Encrypt: gratuit, auto-renew, trusted
- HSTS: force HTTPS, protection downgrade attacks
- Certificate pinning (post-MVP): protection CA compromise

**Cons√©quences:**
- Aucune communication en clair (HTTP interdit)
- Dev local: certificats self-signed ok (pas prod)
- Monitoring expiration certificats (alerte 30j avant)

---

#### 10.5 - Conformit√© RGPD

**Decision:** Data export, account deletion (soft delete 30j), opt-in consent analytics

**Droits Utilisateur (RGPD Articles 15, 17, 20):**

**1. Droit d'acc√®s (Article 15):**
```typescript
// Export complet donn√©es utilisateur
GET /user/export

Response: ZIP file containing:
  - user_data.json (profile, metadata)
  - captures.json (toutes les captures)
  - audio_files/ (tous les fichiers audio)
  - thoughts.json (digestions, r√©sum√©s)
  - todos.json (actions)
  - ideas.json (id√©es)
  - projects.json (projets)
```

**2. Droit √† l'effacement (Article 17):**
```typescript
// Suppression compte
DELETE /user/account

Process:
1. Soft delete (30 jours de gr√¢ce)
   ‚Üí account.state = 'pending_deletion'
   ‚Üí account.deletion_date = NOW() + 30 days
   ‚Üí User peut annuler dans les 30j

2. Hard delete (apr√®s 30 jours, cron job)
   ‚Üí Suppression DB: CASCADE sur toutes les tables
   ‚Üí Suppression S3: audio files
   ‚Üí Suppression Redis: cache
   ‚Üí Anonymisation logs: remplace userId par 'deleted_user'

3. Exceptions:
   ‚Üí Logs applicatifs: 90 jours (debugging)
   ‚Üí Backups: 7 jours (restauration)
   ‚Üí Legal hold: si proc√©dure judiciaire en cours
```

**3. Consentement (Article 6):**
```typescript
// Onboarding - Opt-in explicite
const consents = {
  required: [
    {
      type: 'terms_of_service',
      mandatory: true,
      description: "Conditions d'utilisation Pensine"
    },
    {
      type: 'data_processing',
      mandatory: true,
      description: "Traitement donn√©es pour fonctionnement app"
    }
  ],
  optional: [
    {
      type: 'analytics',
      mandatory: false,
      description: "Statistiques usage anonymis√©es (am√©lioration produit)",
      default: false  // Opt-in, pas opt-out
    },
    {
      type: 'crash_reports',
      mandatory: false,
      description: "Rapports crash automatiques (Sentry)",
      default: true   // Recommand√© mais optionnel
    }
  ]
};

// User peut modifier consentements apr√®s onboarding
PUT /user/consents
{
  analytics: false,
  crash_reports: true
}
```

**4. Portabilit√© (Article 20):**
```json
// Format export JSON structur√©
{
  "version": "1.0.0",
  "exported_at": "2026-01-13T10:00:00Z",
  "user": {
    "id": "uuid",
    "email": "user@example.com",
    "created_at": "2026-01-01T00:00:00Z"
  },
  "captures": [
    {
      "id": "uuid",
      "type": "audio",
      "captured_at": "2026-01-12T15:30:00Z",
      "audio_file": "audio_files/capture_123.m4a",
      "transcription": "...",
      "summary": "...",
      "tags": ["business", "idea"]
    }
  ],
  "todos": [...],
  "ideas": [...]
}
```

**Rationale:**
- Conformit√© l√©gale UE obligatoire
- Export JSON + audio = portabilit√© compl√®te
- Soft delete 30j = protection erreur utilisateur
- Opt-in analytics = respect vie priv√©e
- Anonymisation logs = balance s√©curit√©/privacy

**Documentation Utilisateur:**
- Privacy Policy (fran√ßais + anglais)
- Data Processing Agreement (si B2B)
- FAQ RGPD (droits, proc√©dures)

---

**Cons√©quences globales ADR-010:**
- Protection donn√©es sensibles multi-niveaux
- Conformit√© RGPD compl√®te
- Balance s√©curit√© / UX / performance
- Co√ªt infrastructure: +10% (chiffrement, certificats)
- Maintenance: monitoring certificats, audit logs, RGPD requests

---

### ADR-011: Performance Optimization Strategy

**Status:** ‚úÖ ACCEPT√â

**Context:** D√©finir les strat√©gies d'optimisation pour respecter les NFRs de performance critiques (capture < 500ms, transcription < 2x dur√©e audio, digestion < 30s).

**Decision:** 3 d√©cisions valid√©es pour optimisation globale.

---

#### 11.1 - Redis Caching Strategy

**Decision:** Cache strat√©gique cibl√©, pas de cache agressif

**Usage de Redis :**

```typescript
// 1. Session cache (JWT payload d√©cod√©)
const sessionKey = `session:${userId}`;
await redis.setex(sessionKey, 900, JSON.stringify(sessionData));  // 15min TTL

// 2. User profile cache (fr√©quemment acc√©d√©)
const userKey = `user:${userId}`;
await redis.setex(userKey, 3600, JSON.stringify(userProfile));  // 1h TTL

// 3. Digestion results cache (temps r√©el r√©cent)
const digestKey = `digest:${captureId}`;
await redis.setex(digestKey, 1800, JSON.stringify(digestResult));  // 30min TTL

// 4. Concordance scores (calculs co√ªteux)
const concordanceKey = `concordance:${ideaId}`;
await redis.setex(concordanceKey, 3600, JSON.stringify(scores));  // 1h TTL
```

**Ce qui N'est PAS cach√© :**
- ‚ùå Captures (changent fr√©quemment, mobile offline-first a d√©j√† le cache)
- ‚ùå Todos (√©tat utilisateur volatile)
- ‚ùå Ideas/Projects (concordance dynamique)

**Invalidation :**

```typescript
// Invalidation cibl√©e (pas de flush global)
class CacheService {
  async invalidateUser(userId: string) {
    await redis.del(`user:${userId}`);
    await redis.del(`session:${userId}`);
  }

  async invalidateDigest(captureId: string) {
    await redis.del(`digest:${captureId}`);
  }

  // Pattern-based invalidation (attention performance)
  async invalidateConcordanceForIdea(ideaId: string) {
    const keys = await redis.keys(`concordance:*${ideaId}*`);
    if (keys.length > 0) {
      await redis.del(...keys);
    }
  }
}
```

**Rationale :**
- Cache UNIQUEMENT les hot paths (session, profile)
- TTL courts pour √©viter stale data
- Mobile a d√©j√† cache complet (WatermelonDB)
- Redis = cache serveur uniquement
- MVP mono-user = moins de pression cache

**Metrics √† monitorer :**
- Cache hit rate (objectif > 80% pour session/user)
- Latence avec/sans cache
- Memory usage Redis

---

#### 11.2 - Lazy Loading Strategies

**Decision:** Lazy loading cibl√© UI + data, pagination backend

**Mobile (UI Lazy Loading) :**

```typescript
// 1. Liste captures avec virtualisation
import { FlashList } from '@shopify/flash-list';

<FlashList
  data={captures}
  renderItem={({ item }) => <CaptureCard capture={item} />}
  estimatedItemSize={120}
  // Virtualization automatique (ne render que visible)
/>

// 2. Images lazy avec blurhash
<Image
  source={{ uri: capture.thumbnailUrl }}
  placeholder={{ blurhash: capture.blurhash }}
  transition={200}
/>

// 3. Audio player lazy (charg√© au tap)
const AudioPlayer = lazy(() => import('./AudioPlayer'));

<Suspense fallback={<AudioPlayerSkeleton />}>
  {isPlaying && <AudioPlayer uri={audioUri} />}
</Suspense>

// 4. Tabs lazy (pas de pr√©-chargement)
// Tab Actions charg√© seulement quand user tape dessus
<Tab.Navigator lazy={true}>
  <Tab.Screen name="Feed" component={FeedScreen} />
  <Tab.Screen name="Actions" component={ActionsScreen} />  {/* Lazy */}
  <Tab.Screen name="Projects" component={ProjectsScreen} />  {/* Lazy */}
</Tab.Navigator>
```

**Backend (Data Pagination) :**

```typescript
// API avec cursor-based pagination
GET /captures?cursor=c123&limit=20

// Query optimis√© avec index
const captures = await db.captures
  .where('user_id', userId)
  .where('created_at', '<', cursorDate)
  .orderBy('created_at', 'desc')
  .limit(20);

Response:
{
  data: [...],
  nextCursor: 'c143',
  hasMore: true
}

// Mobile incremental load
class CaptureList {
  async loadMore() {
    if (this.isLoading || !this.hasMore) return;

    const response = await api.getCaptures({
      cursor: this.nextCursor,
      limit: 20
    });

    this.captures.push(...response.data);
    this.nextCursor = response.nextCursor;
    this.hasMore = response.hasMore;
  }
}
```

**WatermelonDB Lazy Queries :**

```typescript
// Ne charge QUE ce qui est affich√© (pas toute la DB)
const visibleCaptures = await database.get('captures')
  .query(
    Q.where('created_at', Q.gte(last30Days)),
    Q.sortBy('created_at', Q.desc),
    Q.take(50)  // Limite initiale
  )
  .observe();  // R√©actif

// Expand si user scroll
```

**Rationale :**
- Capture < 500ms : pas de chargement lourd au lancement
- FlashList : performance lists longues (1000+ items)
- Pagination backend : √©vite OOM si 10k+ captures
- Tabs lazy : √©conomie m√©moire
- Blurhash : perception vitesse (placeholder imm√©diat)

---

#### 11.3 - Audio Compression & Formats

**Decision:** AAC-LC compression, qualit√© adaptative, nettoyage automatique

**Format Audio :**

```typescript
// Recording config (Expo AV)
const recordingOptions = {
  android: {
    extension: '.m4a',
    outputFormat: Audio.AndroidOutputFormat.MPEG_4,
    audioEncoder: Audio.AndroidAudioEncoder.AAC,
    sampleRate: 44100,
    numberOfChannels: 1,  // Mono (voix)
    bitRate: 64000,       // 64 kbps (balance qualit√©/taille)
  },
  ios: {
    extension: '.m4a',
    outputFormat: Audio.IOSOutputFormat.MPEG4AAC,
    audioQuality: Audio.IOSAudioQuality.MEDIUM,
    sampleRate: 44100,
    numberOfChannels: 1,
    bitRate: 64000,
    linearPCMBitDepth: 16,
    linearPCMIsBigEndian: false,
    linearPCMIsFloat: false,
  },
  web: {
    mimeType: 'audio/webm;codecs=opus',
    bitsPerSecond: 64000,
  }
};
```

**Tailles Attendues :**

```
Dur√©e    | Taille (64 kbps mono)
---------|----------------------
30s      | ~240 KB
1 min    | ~480 KB
2 min    | ~960 KB
5 min    | ~2.4 MB

5 captures/jour √ó 1 min √ó 30 jours = ~72 MB/mois
```

**Compression Serveur (Post-Upload) :**

```typescript
// Optionnel : re-compression serveur pour stockage long terme
class AudioProcessor {
  async compressForStorage(audioFile: Buffer): Promise<Buffer> {
    // FFmpeg : AAC 32 kbps pour stockage (qualit√© suffisante)
    return ffmpeg(audioFile)
      .audioCodec('aac')
      .audioBitrate('32k')
      .audioChannels(1)
      .toBuffer();
  }
}

// R√©duction: 64 kbps ‚Üí 32 kbps = 50% √©conomie stockage
```

**Nettoyage Local (Mobile) :**

```typescript
// Cleanup audio local apr√®s upload r√©ussi + X jours
class StorageManager {
  async cleanupOldAudio() {
    const threshold = Date.now() - (30 * 24 * 60 * 60 * 1000);  // 30 jours

    const oldCaptures = await db.captures.query(
      Q.where('upload_state', 'completed'),
      Q.where('captured_at', Q.lt(threshold))
    );

    for (const capture of oldCaptures) {
      // Supprimer fichier local
      await FileSystem.deleteAsync(capture.audioLocalUri, { idempotent: true });

      // Garder metadata + URL remote
      await capture.update(c => {
        c.audioLocalUri = null;  // Indique "plus en local"
      });
    }
  }
}

// Cron: tous les jours √† 3h du matin
```

**Streaming (Post-MVP) :**

```typescript
// Si fichier pas en local, stream depuis serveur
async playAudio(capture: Capture) {
  const uri = capture.audioLocalUri
    ? capture.audioLocalUri           // Local (rapide)
    : capture.audioRemoteUrl;         // Stream serveur (si cleanup)

  await Audio.Sound.createAsync(
    { uri },
    { shouldPlay: true }
  );
}
```

**Rationale :**
- AAC-LC : meilleur ratio qualit√©/taille pour voix
- 64 kbps mono : qualit√© suffisante pour transcription Whisper
- Cleanup 30j : √©conomie stockage mobile (128 GB = limit√©)
- Format M4A : compatible iOS/Android/Web
- Mono channel : voix uniquement (pas besoin st√©r√©o)

**Whisper Performance :**
- Qualit√© audio n'impacte pas beaucoup pr√©cision transcription
- 64 kbps AAC > suffisant pour Whisper
- Compression r√©duit aussi temps upload

---

**Cons√©quences globales ADR-011:**
- NFRs performance respect√©es (capture < 500ms, chargement < 1s)
- √âconomie bande passante : ~50% (compression audio)
- √âconomie stockage mobile : cleanup automatique
- UX fluide : lazy loading + virtualisation
- Cache cibl√© : pas de over-caching

---

### ADR-012: Queue Management avec RabbitMQ

**Status:** ‚úÖ ACCEPT√â

**Context:** G√©rer les t√¢ches asynchrones (transcription, digestion IA, concordance) avec RabbitMQ pour isolation pannes et r√©silience.

**Decision:** 4 d√©cisions valid√©es pour gestion compl√®te des queues.

---

#### 12.1 - Dead Letter Queues (DLQ)

**Decision:** DLQ syst√©matique pour chaque queue m√©tier

**Architecture :**

```typescript
// Configuration RabbitMQ
const queueConfig = {
  // Queue principale
  digestion: {
    name: 'digestion.queue',
    durable: true,
    arguments: {
      'x-dead-letter-exchange': 'dlx',
      'x-dead-letter-routing-key': 'digestion.dlq',
      'x-message-ttl': 300000,  // 5 min max processing
    }
  },

  // Dead Letter Queue
  digestion_dlq: {
    name: 'digestion.dlq',
    durable: true,
    // Pas de retry automatique depuis DLQ
  }
};

// Transcription queue
const transcriptionConfig = {
  name: 'transcription.queue',
  durable: true,
  arguments: {
    'x-dead-letter-exchange': 'dlx',
    'x-dead-letter-routing-key': 'transcription.dlq',
    'x-message-ttl': 600000,  // 10 min max (audio long)
  }
};

// Concordance queue
const concordanceConfig = {
  name: 'concordance.queue',
  durable: true,
  arguments: {
    'x-dead-letter-exchange': 'dlx',
    'x-dead-letter-routing-key': 'concordance.dlq',
    'x-message-ttl': 60000,  // 1 min max
  }
};
```

**Consumer avec ACK manuel :**

```typescript
@Injectable()
class DigestionConsumer {
  @RabbitSubscribe({
    exchange: 'pensine',
    routingKey: 'digestion.queue',
    queue: 'digestion.queue',
  })
  async handleDigestion(msg: DigestionMessage, context: RabbitContext) {
    const channel = context.getChannelRef();
    const originalMsg = context.getMessage();

    try {
      // Traitement
      const result = await this.digestionService.process(msg);

      // ACK success
      channel.ack(originalMsg);

      // Publier r√©sultat
      await this.eventBus.publish(new ThoughtDigested(result));

    } catch (error) {
      // Log erreur
      this.logger.error('Digestion failed', { msg, error });

      // NACK ‚Üí va en DLQ
      channel.nack(originalMsg, false, false);

      // Notifier erreur
      await this.notificationService.sendError(msg.userId, 'digestion_failed');
    }
  }
}
```

**Monitoring DLQ :**

```typescript
// Cron job : monitorer DLQ toutes les 10 minutes
@Cron('*/10 * * * *')
async monitorDeadLetters() {
  const dlqStats = await this.rabbitService.getQueueStats([
    'digestion.dlq',
    'transcription.dlq',
    'concordance.dlq'
  ]);

  for (const [queue, stats] of Object.entries(dlqStats)) {
    if (stats.messages > 0) {
      // Alerte si messages en DLQ
      await this.alertService.send({
        severity: 'warning',
        message: `${stats.messages} messages in ${queue}`,
        queue,
        count: stats.messages
      });
    }
  }
}
```

**Rationale :**
- DLQ √©vite perte de messages √©chou√©s
- TTL emp√™che blocage infini (timeout)
- NACK sans requeue ‚Üí DLQ directement
- Monitoring DLQ = d√©tection erreurs syst√©miques

---

#### 12.2 - Retry Logic & Exponential Backoff

**Decision:** Retry avec Fibonacci backoff, max 5 attempts

**Retry Headers (RabbitMQ) :**

```typescript
// Message avec retry count dans headers
interface MessageWithRetry {
  payload: any;
  headers: {
    'x-retry-count': number;
    'x-first-attempt': number;  // Timestamp
    'x-last-attempt': number;
  };
}

// Publisher ajoute headers
await this.rabbitService.publish('digestion.queue', {
  captureId: 'c123',
  userId: 'u456',
}, {
  headers: {
    'x-retry-count': 0,
    'x-first-attempt': Date.now(),
    'x-last-attempt': Date.now(),
  }
});
```

**Consumer avec retry logic :**

```typescript
@Injectable()
class DigestionConsumer {
  private readonly MAX_RETRIES = 5;
  private readonly FIBONACCI_DELAYS = [1, 1, 2, 3, 5, 8];  // Secondes

  async handleDigestion(msg: MessageWithRetry, context: RabbitContext) {
    const channel = context.getChannelRef();
    const originalMsg = context.getMessage();
    const retryCount = msg.headers['x-retry-count'] || 0;

    try {
      await this.digestionService.process(msg.payload);
      channel.ack(originalMsg);

    } catch (error) {
      // V√©rifier si erreur retryable
      const isRetryable = this.isRetryableError(error);

      if (!isRetryable || retryCount >= this.MAX_RETRIES) {
        // Non retryable ou max retries ‚Üí DLQ
        this.logger.error('Max retries reached or non-retryable', { msg, error });
        channel.nack(originalMsg, false, false);  // ‚Üí DLQ
        return;
      }

      // Retry avec backoff
      const delaySeconds = this.FIBONACCI_DELAYS[retryCount];

      // Re-publier avec delay
      await this.retryWithDelay(msg, retryCount + 1, delaySeconds);

      // ACK message original (sera re-trait√© via republication)
      channel.ack(originalMsg);
    }
  }

  private async retryWithDelay(
    msg: MessageWithRetry,
    newRetryCount: number,
    delaySeconds: number
  ) {
    await this.rabbitService.publish(
      'digestion.queue',
      msg.payload,
      {
        headers: {
          'x-retry-count': newRetryCount,
          'x-first-attempt': msg.headers['x-first-attempt'],
          'x-last-attempt': Date.now(),
        },
        // Delayed message exchange plugin
        delay: delaySeconds * 1000,
      }
    );
  }

  private isRetryableError(error: Error): boolean {
    // Erreurs temporaires = retryable
    const retryableErrors = [
      'ECONNREFUSED',     // LLM API down
      'ETIMEDOUT',        // Timeout r√©seau
      'ENOTFOUND',        // DNS temporaire
      '429',              // Rate limit LLM
      '503',              // Service unavailable
    ];

    return retryableErrors.some(code =>
      error.message.includes(code) || error.name.includes(code)
    );
  }
}
```

**RabbitMQ Delayed Message Exchange :**

```bash
# Installation plugin
rabbitmq-plugins enable rabbitmq_delayed_message_exchange

# Configuration exchange
{
  "name": "delayed_exchange",
  "type": "x-delayed-message",
  "durable": true,
  "arguments": {
    "x-delayed-type": "direct"
  }
}
```

**Rationale :**
- Fibonacci backoff : progression douce (1s, 1s, 2s, 3s, 5s, 8s)
- Max 5 retries : √©vite boucle infinie
- Erreurs retryables vs permanentes : strat√©gie diff√©renci√©e
- Delayed exchange : √©vite polling (natif RabbitMQ)

---

#### 12.3 - Queue Prioritization

**Decision:** Queues s√©par√©es avec consommateurs prioritaires

**Architecture multi-queues :**

```typescript
// Queues par priorit√© m√©tier
const QUEUES = {
  // CRITICAL : impact user imm√©diat
  transcription: {
    name: 'transcription.queue',
    priority: 'critical',
    consumers: 3,  // 3 workers d√©di√©s
  },

  // HIGH : exp√©rience user
  digestion: {
    name: 'digestion.queue',
    priority: 'high',
    consumers: 2,
  },

  // MEDIUM : background
  concordance: {
    name: 'concordance.queue',
    priority: 'medium',
    consumers: 1,
  },

  // LOW : batch
  analytics: {
    name: 'analytics.queue',
    priority: 'low',
    consumers: 1,
  },
};
```

**Consumer avec scaling dynamique :**

```typescript
// NestJS worker scalable
@Module({
  imports: [
    RabbitMQModule.forRoot({
      exchanges: [{ name: 'pensine', type: 'topic' }],
      uri: process.env.RABBITMQ_URI,
      connectionInitOptions: { wait: false },
    }),
  ],
})
class WorkersModule implements OnModuleInit {
  constructor(private rabbitService: AmqpConnection) {}

  onModuleInit() {
    // Spawn consumers selon config
    for (const [name, config] of Object.entries(QUEUES)) {
      for (let i = 0; i < config.consumers; i++) {
        this.spawnConsumer(name, i);
      }
    }
  }

  private spawnConsumer(queueName: string, workerId: number) {
    this.logger.log(`Spawning consumer ${queueName}:${workerId}`);
    // Consumer s'enregistre automatiquement via @RabbitSubscribe
  }
}
```

**Metrics & Auto-scaling (Post-MVP) :**

```typescript
// Monitorer queue depth
@Cron('*/1 * * * *')  // Toutes les minutes
async monitorQueueDepth() {
  const stats = await this.rabbitService.getQueueStats('digestion.queue');

  if (stats.messages > 100) {
    // Queue satur√©e ‚Üí augmenter consumers
    await this.scalingService.scaleUp('digestion', targetConsumers: 4);
  }

  if (stats.messages < 10 && stats.consumers > 2) {
    // Queue vide ‚Üí r√©duire consumers
    await this.scalingService.scaleDown('digestion', targetConsumers: 2);
  }
}
```

**Rationale :**
- Queues s√©par√©es : isolation pannes (transcription down ‚â† digestion bloqu√©e)
- Consumers d√©di√©s : garantie traitement prioritaire
- Scaling par queue : optimisation ressources
- MVP : consumers fixes, Post-MVP : auto-scaling

---

#### 12.4 - Monitoring & Alerting

**Decision:** M√©triques RabbitMQ + alertes proactives

**M√©triques RabbitMQ √† tracker :**

```typescript
interface QueueMetrics {
  // Volume
  messages: number;           // Messages en attente
  messagesReady: number;      // Pr√™ts √† consommer
  messagesUnacked: number;    // En cours de traitement

  // Performance
  publishRate: number;        // Msgs/sec publi√©s
  consumeRate: number;        // Msgs/sec consomm√©s
  ackRate: number;            // Msgs/sec acknowledg√©s

  // Consumers
  consumers: number;          // Consumers actifs
  consumerUtilisation: number; // % utilisation

  // Dur√©e
  avgProcessingTime: number;  // Temps moyen traitement
}
```

**Collecte m√©triques (Prometheus) :**

```typescript
// NestJS Prometheus exporter
@Injectable()
class RabbitMetricsCollector {
  private readonly gauges = {
    queueDepth: new Gauge({
      name: 'rabbitmq_queue_messages',
      help: 'Messages in queue',
      labelNames: ['queue'],
    }),
    consumers: new Gauge({
      name: 'rabbitmq_queue_consumers',
      help: 'Active consumers',
      labelNames: ['queue'],
    }),
  };

  @Cron('*/30 * * * * *')  // Toutes les 30s
  async collectMetrics() {
    for (const queueName of Object.keys(QUEUES)) {
      const stats = await this.rabbitService.getQueueStats(queueName);

      this.gauges.queueDepth.set({ queue: queueName }, stats.messages);
      this.gauges.consumers.set({ queue: queueName }, stats.consumers);
    }
  }
}
```

**Alertes (crit√®res) :**

```typescript
const ALERTS = {
  queueSaturated: {
    condition: 'queue_depth > 500',
    severity: 'warning',
    message: 'Queue satur√©e, scaling n√©cessaire',
  },

  consumerDown: {
    condition: 'consumers == 0 && queue_depth > 0',
    severity: 'critical',
    message: 'Aucun consumer actif',
  },

  dlqNotEmpty: {
    condition: 'dlq_depth > 0',
    severity: 'warning',
    message: 'Messages en DLQ n√©cessitent investigation',
  },

  slowProcessing: {
    condition: 'avg_processing_time > 60000',  // 60s
    severity: 'warning',
    message: 'Traitement lent d√©tect√©',
  },
};
```

**Dashboard Grafana (KPIs) :**

```
üìä RabbitMQ Dashboard

‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ Queue Depth (real-time)                 ‚îÇ
‚îÇ ‚ñÇ‚ñÉ‚ñÖ‚ñá‚ñà‚ñá‚ñÖ‚ñÉ‚ñÇ Digestion: 23 msgs           ‚îÇ
‚îÇ ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ Transcription: 5 msgs        ‚îÇ
‚îÇ ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ Concordance: 0 msgs          ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò

‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ Throughput (msgs/min)                   ‚îÇ
‚îÇ Published: 120 msg/min                  ‚îÇ
‚îÇ Consumed: 115 msg/min                   ‚îÇ
‚îÇ DLQ: 2 msg/min ‚ö†Ô∏è                      ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò

‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ Processing Time (avg)                   ‚îÇ
‚îÇ Digestion: 12.3s                        ‚îÇ
‚îÇ Transcription: 45s                      ‚îÇ
‚îÇ Concordance: 3.2s                       ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

**Rationale :**
- Prometheus : m√©triques time-series standard
- Grafana : visualisation temps r√©el
- Alertes proactives : d√©tection avant incident
- KPIs m√©tier : digestion < 30s, transcription < 2x dur√©e

---

**Cons√©quences globales ADR-012:**
- R√©silience : DLQ + retry √©vitent perte messages
- Performance : queues prioritaires + scaling
- Observabilit√© : m√©triques + alertes proactives
- Maintenance : isolation pannes par queue
- Co√ªt : RabbitMQ l√©ger (< 512 MB RAM pour MVP)

---

### ADR-013: Notification System

**Status:** ‚úÖ ACCEPT√â

**Context:** Notifier l'utilisateur des √©v√©nements importants (digestion compl√©t√©e, concordance d√©tect√©e, todo reminder) sans spammer.

**Decision:** Local notifications MVP, push notifications Post-MVP, opt-in/opt-out granulaire

**Architecture Notifications :**

```typescript
// Types de notifications
enum NotificationType {
  DIGESTION_COMPLETED = 'digestion_completed',
  TRANSCRIPTION_FAILED = 'transcription_failed',
  CONCORDANCE_DETECTED = 'concordance_detected',
  TODO_REMINDER = 'todo_reminder',
  PROJECT_SUGGESTED = 'project_suggested',
}

// Pr√©f√©rences user (opt-in/opt-out)
interface NotificationPreferences {
  digestionCompleted: boolean;    // Default: true
  concordanceDetected: boolean;   // Default: true
  todoReminders: boolean;         // Default: true
  projectSuggested: boolean;      // Default: true

  // Timing
  quietHours: {
    enabled: boolean;
    start: string;  // "22:00"
    end: string;    // "08:00"
  };
}
```

**MVP : Local Notifications Uniquement**

```typescript
// Mobile (Expo Notifications)
import * as Notifications from 'expo-notifications';

class NotificationService {
  async scheduleLocal(
    type: NotificationType,
    title: string,
    body: string,
    data?: any,
    triggerSeconds: number = 0
  ) {
    // V√©rifier pr√©f√©rences user
    const prefs = await this.getPreferences();
    if (!this.isEnabled(type, prefs)) return;

    // V√©rifier quiet hours
    if (this.isQuietHours(prefs.quietHours)) {
      // Reporter apr√®s quiet hours
      triggerSeconds = this.calculateDelayAfterQuietHours(prefs.quietHours);
    }

    await Notifications.scheduleNotificationAsync({
      content: {
        title,
        body,
        data,
        sound: true,
        badge: 1,
      },
      trigger: triggerSeconds === 0
        ? null  // Imm√©diat
        : { seconds: triggerSeconds }
    });
  }

  // Exemples d'usage
  async notifyDigestionCompleted(captureId: string) {
    await this.scheduleLocal(
      NotificationType.DIGESTION_COMPLETED,
      '‚ú® Capture dig√©r√©e',
      'Votre capture a √©t√© analys√©e et des id√©es ont √©t√© extraites',
      { captureId },
      0  // Imm√©diat
    );
  }

  async notifyTodoReminder(todo: Todo) {
    const delay = this.calculateDelayUntilDeadline(todo.deadline);

    await this.scheduleLocal(
      NotificationType.TODO_REMINDER,
      '‚è∞ Rappel',
      todo.description,
      { todoId: todo.id },
      delay
    );
  }

  async notifyProjectSuggested(project: Project) {
    await this.scheduleLocal(
      NotificationType.PROJECT_SUGGESTED,
      'üå± Nouveau pattern d√©tect√©',
      `"${project.name}" - ${project.ideaIds.length} id√©es connexes`,
      { projectId: project.id },
      0
    );
  }
}
```

**Post-MVP : Push Notifications (Firebase)**

```typescript
// Backend envoie push via FCM
class PushNotificationService {
  async sendPush(
    userId: string,
    type: NotificationType,
    title: string,
    body: string,
    data?: any
  ) {
    const user = await this.userService.findById(userId);

    // R√©cup√©rer FCM token
    const fcmToken = user.fcmToken;
    if (!fcmToken) return;  // User pas enregistr√© pour push

    // V√©rifier pr√©f√©rences
    const prefs = await this.preferencesService.get(userId);
    if (!this.isEnabled(type, prefs)) return;

    // Envoyer via FCM
    await this.fcm.send({
      token: fcmToken,
      notification: {
        title,
        body,
      },
      data,
      android: {
        priority: 'high',
        notification: {
          sound: 'default',
          channelId: 'pensine_default',
        },
      },
      apns: {
        payload: {
          aps: {
            sound: 'default',
            badge: 1,
          },
        },
      },
    });
  }
}
```

**Rationale :**
- MVP : local notifications suffisent (mono-user, app ouverte fr√©quemment)
- Post-MVP : push pour engagement (concordance d√©tect√©e pendant app ferm√©e)
- Opt-in/opt-out : respect pr√©f√©rences user
- Quiet hours : pas de spam nocturne

---

### ADR-014: Storage Management

**Status:** ‚úÖ ACCEPT√â

**Context:** G√©rer le stockage audio (mobile + cloud) avec retention policy et cleanup automatique.

**Decision:** 3 d√©cisions pour optimisation stockage

---

#### 14.1 - Audio Retention Policy

**Decision:** Mobile 30 jours, Cloud permanent (avec compression)

**Lifecycle Audio :**

```
Capture ‚Üí [Mobile 64kbps] ‚Üí Upload ‚Üí [Cloud 32kbps compressed]
   ‚Üì                              ‚Üì
Cleanup apr√®s 30j          Permanent (tant que compte actif)
```

**Mobile Cleanup :**

```typescript
class StorageManager {
  // Cron quotidien √† 3h du matin
  @Cron('0 3 * * *')
  async cleanupOldAudio() {
    const threshold = Date.now() - (30 * 24 * 60 * 60 * 1000);  // 30 jours

    const toCleanup = await db.captures.query(
      Q.where('upload_state', 'completed'),  // Upload r√©ussi
      Q.where('captured_at', Q.lt(threshold)),  // > 30 jours
      Q.where('audio_local_uri', Q.notEq(null))  // Fichier existe
    );

    let freedSpace = 0;

    for (const capture of toCleanup) {
      try {
        // R√©cup√©rer taille fichier avant suppression
        const fileInfo = await FileSystem.getInfoAsync(capture.audioLocalUri);
        if (fileInfo.exists) {
          freedSpace += fileInfo.size;

          // Supprimer fichier
          await FileSystem.deleteAsync(capture.audioLocalUri, { idempotent: true });

          // Mettre √† jour record (garder metadata)
          await capture.update(c => {
            c.audioLocalUri = null;
          });
        }
      } catch (error) {
        this.logger.error('Cleanup failed', { captureId: capture.id, error });
      }
    }

    this.logger.info(`Cleanup freed ${(freedSpace / 1024 / 1024).toFixed(2)} MB`);
  }

  // User peut d√©clencher cleanup manuel
  async cleanupManual() {
    // M√™me logique mais avec confirmation user
  }
}
```

**Cloud Permanent avec Compression :**

```typescript
// Backend : compression post-upload
class AudioStorageService {
  async handleAudioUpload(file: Express.Multer.File, captureId: string) {
    // 1. Upload original temporaire
    const originalKey = `audio/temp/${captureId}.m4a`;
    await this.s3.upload(originalKey, file.buffer);

    // 2. Compression FFmpeg (64kbps ‚Üí 32kbps)
    const compressed = await this.compressAudio(file.buffer);

    // 3. Upload compressed permanent
    const permanentKey = `audio/${captureId}.m4a`;
    await this.s3.upload(permanentKey, compressed);

    // 4. Supprimer original
    await this.s3.delete(originalKey);

    // 5. Retourner URL permanent
    return this.s3.getSignedUrl(permanentKey);
  }

  private async compressAudio(buffer: Buffer): Promise<Buffer> {
    return new Promise((resolve, reject) => {
      ffmpeg(buffer)
        .audioCodec('aac')
        .audioBitrate('32k')
        .audioChannels(1)
        .on('end', () => resolve(outputBuffer))
        .on('error', reject)
        .run();
    });
  }
}
```

**Rationale :**
- 30 jours mobile : balance stockage/re-√©coute (user peut re-√©couter r√©cent)
- Cloud permanent : aucune perte de donn√©es, compliance RGPD
- Compression cloud : √©conomie 50% stockage (64kbps ‚Üí 32kbps)

---

#### 14.2 - Quotas Utilisateur

**Decision:** Pas de limite MVP, monitoring usage, quotas Post-MVP si abuse

**Monitoring Usage :**

```typescript
// Backend : tracker usage par user
interface UserStorageStats {
  userId: string;
  capturesCount: number;
  totalAudioSizeMB: number;
  averageCaptureSizeMB: number;
  oldestCapture: Date;
  newestCapture: Date;
}

class StorageAnalytics {
  @Cron('0 0 * * 0')  // Hebdomadaire (dimanche minuit)
  async computeStorageStats() {
    const users = await this.userService.findAll();

    for (const user of users) {
      const stats = await this.computeUserStats(user.id);

      // Alerter si usage anormal
      if (stats.totalAudioSizeMB > 5000) {  // > 5 GB
        await this.alertService.send({
          severity: 'info',
          message: `User ${user.id} has ${stats.totalAudioSizeMB} MB audio`,
          userId: user.id,
        });
      }

      // Stocker stats pour analytics
      await this.analyticsService.save(stats);
    }
  }
}
```

**Quotas Post-MVP (si n√©cessaire) :**

```typescript
const QUOTAS = {
  free: {
    maxCaptures: null,        // Illimit√©
    maxAudioSizeMB: 1000,     // 1 GB
    maxAudioDurationMin: null, // Illimit√©
  },

  premium: {
    maxCaptures: null,
    maxAudioSizeMB: 10000,    // 10 GB
    maxAudioDurationMin: null,
  },
};

class QuotaService {
  async checkQuota(userId: string, audioSizeMB: number): Promise<boolean> {
    const user = await this.userService.findById(userId);
    const quota = QUOTAS[user.plan];

    const currentUsage = await this.getCurrentUsage(userId);

    if (currentUsage.totalAudioSizeMB + audioSizeMB > quota.maxAudioSizeMB) {
      // Quota d√©pass√©
      await this.notificationService.send(userId, {
        type: 'quota_exceeded',
        message: 'Quota stockage atteint',
      });
      return false;
    }

    return true;
  }
}
```

**Rationale MVP sans quotas :**
- Mono-user = usage limit√© naturellement
- 5 captures/jour √ó 1min √ó 365j √ó 32kbps = ~350 MB/an (acceptable)
- Monitoring suffit pour d√©tecter abuse
- Quotas ajout√©s seulement si probl√®me identifi√©

---

#### 14.3 - Media Optimization

**Decision:** Thumbnails blurhash, lazy loading, adaptive quality

**Blurhash pour Perception Vitesse :**

```typescript
// Backend : g√©n√©rer blurhash lors digestion
class DigestionService {
  async process(capture: Capture) {
    // Si capture contient image
    if (capture.type === 'image') {
      const blurhash = await this.generateBlurhash(capture.imageFile);

      return {
        ...digest,
        blurhash,  // String compact (20-30 chars)
      };
    }
  }

  private async generateBlurhash(imageBuffer: Buffer): Promise<string> {
    const { data, info } = await sharp(imageBuffer)
      .resize(32, 32, { fit: 'inside' })
      .ensureAlpha()
      .raw()
      .toBuffer({ resolveWithObject: true });

    return encode(
      new Uint8ClampedArray(data),
      info.width,
      info.height,
      4,  // Components X
      3   // Components Y
    );
  }
}

// Mobile : afficher blurhash pendant chargement
<Image
  source={{ uri: capture.imageUrl }}
  placeholder={{ blurhash: capture.blurhash }}
  transition={200}
  style={styles.image}
/>
```

**Adaptive Quality (Post-MVP) :**

```typescript
// Servir audio qualit√© adapt√©e √† connexion
class AdaptiveAudioService {
  async getAudioUrl(captureId: string, quality: 'low' | 'medium' | 'high') {
    const qualityMap = {
      low: '16kbps',     // 2G/slow 3G
      medium: '32kbps',  // 3G/4G
      high: '64kbps',    // WiFi/5G
    };

    const key = `audio/${captureId}_${qualityMap[quality]}.m4a`;
    return this.s3.getSignedUrl(key);
  }
}

// Mobile d√©tecte connexion
const quality = netInfo.type === 'wifi' ? 'high' : 'medium';
const audioUrl = await api.getAudioUrl(captureId, quality);
```

**Rationale :**
- Blurhash : placeholder imm√©diat (perception vitesse)
- Lazy loading : √©conomie bande passante
- Adaptive quality : optimisation connexion lente

---

**Cons√©quences globales ADR-014:**
- Stockage mobile optimis√© : cleanup 30j automatique
- Cloud √©conomique : compression 50%
- Quotas : monitoring sans limite artificielle MVP
- UX : blurhash + lazy loading = fluidit√©

---

### ADR-015: Observability Strategy

**Status:** ‚úÖ ACCEPT√â

**Context:** Monitorer performance, erreurs et usage pour d√©tecter probl√®mes avant impact utilisateur.

**Decision:** Stack observability compl√®te (Logs + Metrics + Tracing + Alertes)

---

#### 15.1 - Logging Strategy

**Decision:** Structured logging (JSON), niveaux appropri√©s, rotation automatique

**Niveaux de Log :**

```typescript
// NestJS Winston logger
const logger = winston.createLogger({
  level: process.env.LOG_LEVEL || 'info',
  format: winston.format.combine(
    winston.format.timestamp(),
    winston.format.errors({ stack: true }),
    winston.format.json()
  ),
  defaultMeta: {
    service: 'pensine-backend',
    environment: process.env.NODE_ENV,
  },
  transports: [
    // Console (d√©veloppement)
    new winston.transports.Console({
      format: winston.format.simple(),
    }),

    // Fichier (production)
    new winston.transports.File({
      filename: 'logs/error.log',
      level: 'error',
      maxsize: 10485760,  // 10 MB
      maxFiles: 5,
      tailable: true,
    }),

    new winston.transports.File({
      filename: 'logs/combined.log',
      maxsize: 10485760,
      maxFiles: 10,
      tailable: true,
    }),
  ],
});
```

**Structured Logging :**

```typescript
// ‚úÖ Bon (structured)
logger.info('Digestion completed', {
  captureId: 'c123',
  userId: 'u456',
  duration: 12.3,
  todosExtracted: 3,
  ideasExtracted: 2,
});

// ‚ùå Mauvais (unstructured)
logger.info(`Digestion completed for capture c123 (12.3s)`);
```

**Sensitive Data Filtering :**

```typescript
// Middleware de filtrage
class SensitiveDataFilter {
  filter(log: any): any {
    const filtered = { ...log };

    // Masquer tokens
    if (filtered.token) {
      filtered.token = this.maskToken(filtered.token);
    }

    // Masquer emails
    if (filtered.email) {
      filtered.email = this.maskEmail(filtered.email);
    }

    // Masquer transcriptions (PII potentiel)
    if (filtered.transcription) {
      filtered.transcription = '[REDACTED]';
    }

    return filtered;
  }

  private maskToken(token: string): string {
    return token.substring(0, 8) + '...';
  }

  private maskEmail(email: string): string {
    const [user, domain] = email.split('@');
    return `${user.substring(0, 2)}***@${domain}`;
  }
}
```

**Rationale :**
- JSON structured : queryable, aggregable
- Rotation automatique : √©vite disques pleins
- PII filtering : conformit√© RGPD
- Niveaux appropri√©s : debug (dev), info (prod), error (toujours)

---

#### 15.2 - Metrics & Monitoring

**Decision:** Prometheus + Grafana, m√©triques RED (Rate, Errors, Duration)

**M√©triques Backend (Prometheus) :**

```typescript
// NestJS Prometheus metrics
@Injectable()
class MetricsService {
  private readonly counters = {
    capturesCreated: new Counter({
      name: 'captures_created_total',
      help: 'Total captures created',
      labelNames: ['type'],  // audio, text, image
    }),

    digestionsCompleted: new Counter({
      name: 'digestions_completed_total',
      help: 'Total digestions completed',
    }),

    digestionsErrored: new Counter({
      name: 'digestions_errored_total',
      help: 'Total digestions failed',
      labelNames: ['error_type'],
    }),
  };

  private readonly gauges = {
    activeUsers: new Gauge({
      name: 'active_users',
      help: 'Currently active users',
    }),

    queueDepth: new Gauge({
      name: 'queue_depth',
      help: 'Messages in queue',
      labelNames: ['queue'],
    }),
  };

  private readonly histograms = {
    digestionDuration: new Histogram({
      name: 'digestion_duration_seconds',
      help: 'Digestion processing time',
      buckets: [1, 5, 10, 20, 30, 60],  // Secondes
    }),

    apiLatency: new Histogram({
      name: 'http_request_duration_seconds',
      help: 'HTTP request latency',
      labelNames: ['method', 'route', 'status'],
      buckets: [0.01, 0.05, 0.1, 0.5, 1, 2, 5],
    }),
  };

  // Instrumentation
  recordCapture(type: string) {
    this.counters.capturesCreated.inc({ type });
  }

  recordDigestionDuration(seconds: number) {
    this.histograms.digestionDuration.observe(seconds);
  }

  recordApiCall(method: string, route: string, status: number, duration: number) {
    this.histograms.apiLatency.observe({ method, route, status }, duration);
  }
}
```

**Dashboard Grafana :**

```
üìä Pensine - Backend Metrics

‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ Request Rate (req/min)                  ‚îÇ
‚îÇ ‚ñÇ‚ñÉ‚ñÖ‚ñá‚ñà‚ñá‚ñÖ‚ñÉ‚ñÇ Current: 45 req/min          ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò

‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ Error Rate (%)                          ‚îÇ
‚îÇ ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ Current: 0.5%                ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò

‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ P50 / P95 / P99 Latency                 ‚îÇ
‚îÇ Digestion: 8s / 18s / 28s               ‚îÇ
‚îÇ API: 50ms / 120ms / 250ms               ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò

‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ Queue Depth (messages)                  ‚îÇ
‚îÇ Digestion: 12                           ‚îÇ
‚îÇ Transcription: 3                        ‚îÇ
‚îÇ Concordance: 0                          ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

**Rationale :**
- RED metrics : standard SRE (Google)
- Histograms : P95/P99 latency (pas juste moyenne)
- Labels : segmentation par type/route/status

---

#### 15.3 - Error Tracking

**Decision:** Sentry pour crash reports + error aggregation

**Sentry Configuration :**

```typescript
// Backend
Sentry.init({
  dsn: process.env.SENTRY_DSN,
  environment: process.env.NODE_ENV,
  tracesSampleRate: 0.1,  // 10% traces (co√ªt)

  beforeSend(event, hint) {
    // Filter PII
    if (event.request?.data) {
      event.request.data = filterSensitiveData(event.request.data);
    }
    return event;
  },

  integrations: [
    new Sentry.Integrations.Http({ tracing: true }),
    new Sentry.Integrations.Prisma({ client: prisma }),
  ],
});

// Mobile
Sentry.init({
  dsn: process.env.EXPO_PUBLIC_SENTRY_DSN,
  enableInExpoDevelopment: false,
  debug: false,

  beforeSend(event) {
    // User opt-out crash reports
    if (!userConsents.crashReports) {
      return null;  // Ne pas envoyer
    }
    return event;
  },
});
```

**Error Contexte Enrichi :**

```typescript
// Ajouter contexte m√©tier aux erreurs
try {
  await this.digestionService.process(capture);
} catch (error) {
  Sentry.withScope(scope => {
    scope.setContext('capture', {
      id: capture.id,
      type: capture.type,
      userId: capture.userId,
      createdAt: capture.createdAt,
    });

    scope.setTag('operation', 'digestion');
    scope.setLevel('error');

    Sentry.captureException(error);
  });

  throw error;
}
```

**Rationale :**
- Sentry : standard industrie, gratuit < 5k events/mois
- Error aggregation : d√©duplication automatique
- Context enrichi : debug plus rapide
- Opt-out : respect consentement user (crash reports optionnel)

---

#### 15.4 - Performance Monitoring

**Decision:** APM l√©ger (Sentry Performance), alertes seuils critiques

**Sentry Performance Monitoring :**

```typescript
// Tracer op√©rations critiques
const transaction = Sentry.startTransaction({
  op: 'digestion',
  name: 'Digest Capture',
});

try {
  // 1. Transcription span
  const transcriptionSpan = transaction.startChild({
    op: 'transcription',
    description: 'Whisper transcription',
  });
  const transcription = await this.whisper.transcribe(audio);
  transcriptionSpan.finish();

  // 2. LLM span
  const llmSpan = transaction.startChild({
    op: 'llm',
    description: 'GPT-4o-mini digestion',
  });
  const digest = await this.llm.digest(transcription);
  llmSpan.finish();

  transaction.setStatus('ok');
} catch (error) {
  transaction.setStatus('internal_error');
  throw error;
} finally {
  transaction.finish();
}
```

**Alertes Performance :**

```typescript
const PERFORMANCE_ALERTS = {
  digestionSlow: {
    condition: 'p95(digestion_duration) > 30s',
    severity: 'warning',
    message: 'Digestion P95 d√©passe 30s (NFR)',
  },

  apiSlow: {
    condition: 'p95(api_latency) > 1s',
    severity: 'warning',
    message: 'API P95 d√©passe 1s',
  },

  transcriptionSlow: {
    condition: 'p95(transcription_duration) > audio_duration * 2',
    severity: 'warning',
    message: 'Transcription P95 d√©passe 2x dur√©e audio (NFR)',
  },
};
```

**Rationale :**
- APM l√©ger : Sentry Performance (pas Datadog co√ªteux pour MVP)
- Distributed tracing : debug probl√®mes cross-service
- Alertes sur NFRs : respecter contraintes performance

---

**Cons√©quences globales ADR-015:**
- Observabilit√© compl√®te : logs + metrics + tracing + errors
- D√©tection proactive : alertes avant impact user
- Debug rapide : contexte enrichi sur erreurs
- Co√ªt ma√Ætris√© : stack gratuit/low-cost MVP (Prometheus + Grafana + Sentry free tier)

---

## Step 5 Architectural Decisions - COMPLET ‚úÖ

**D√©cisions finalis√©es :**
1. ‚úÖ ADR-009 : Sync Patterns (6 sous-d√©cisions)
2. ‚úÖ ADR-010 : Security & Encryption (5 sous-d√©cisions)
3. ‚úÖ ADR-011 : Performance Optimization (3 sous-d√©cisions)
4. ‚úÖ ADR-012 : Queue Management RabbitMQ (4 sous-d√©cisions)
5. ‚úÖ ADR-013 : Notification System
6. ‚úÖ ADR-014 : Storage Management (3 sous-d√©cisions)
7. ‚úÖ ADR-015 : Observability Strategy (4 sous-d√©cisions)

**Total : 25 sous-d√©cisions architecturales document√©es**

---

