---
adr: ADR-012
title: "Queue Management avec RabbitMQ"
date: 2026-01-19
status: "âœ… Accepted"
context: "Phase 3 - Solutioning - Architecture Design"
participants:
  - yohikofox (Product Owner)
  - Winston (Architect)
---

# ADR-012: Queue Management avec RabbitMQ

**Status:** âœ… ACCEPTÃ‰

**Context:** GÃ©rer les tÃ¢ches asynchrones (transcription, digestion IA, concordance) avec RabbitMQ pour isolation pannes et rÃ©silience.

**Decision:** 4 dÃ©cisions validÃ©es pour gestion complÃ¨te des queues.

---

## 12.1 - Dead Letter Queues (DLQ)

**Decision:** DLQ systÃ©matique pour chaque queue mÃ©tier

**Architecture :**

```typescript
// Configuration RabbitMQ
const queueConfig = {
  // Queue principale
  digestion: {
    name: 'digestion.queue',
    durable: true,
    arguments: {
      'x-dead-letter-exchange': 'dlx',
      'x-dead-letter-routing-key': 'digestion.dlq',
      'x-message-ttl': 300000,  // 5 min max processing
    }
  },

  // Dead Letter Queue
  digestion_dlq: {
    name: 'digestion.dlq',
    durable: true,
    // Pas de retry automatique depuis DLQ
  }
};

// Transcription queue
const transcriptionConfig = {
  name: 'transcription.queue',
  durable: true,
  arguments: {
    'x-dead-letter-exchange': 'dlx',
    'x-dead-letter-routing-key': 'transcription.dlq',
    'x-message-ttl': 600000,  // 10 min max (audio long)
  }
};

// Concordance queue
const concordanceConfig = {
  name: 'concordance.queue',
  durable: true,
  arguments: {
    'x-dead-letter-exchange': 'dlx',
    'x-dead-letter-routing-key': 'concordance.dlq',
    'x-message-ttl': 60000,  // 1 min max
  }
};
```

**Consumer avec ACK manuel :**

```typescript
@Injectable()
class DigestionConsumer {
  @RabbitSubscribe({
    exchange: 'pensine',
    routingKey: 'digestion.queue',
    queue: 'digestion.queue',
  })
  async handleDigestion(msg: DigestionMessage, context: RabbitContext) {
    const channel = context.getChannelRef();
    const originalMsg = context.getMessage();

    try {
      // Traitement
      const result = await this.digestionService.process(msg);

      // ACK success
      channel.ack(originalMsg);

      // Publier rÃ©sultat
      await this.eventBus.publish(new ThoughtDigested(result));

    } catch (error) {
      // Log erreur
      this.logger.error('Digestion failed', { msg, error });

      // NACK â†’ va en DLQ
      channel.nack(originalMsg, false, false);

      // Notifier erreur
      await this.notificationService.sendError(msg.userId, 'digestion_failed');
    }
  }
}
```

**Monitoring DLQ :**

```typescript
// Cron job : monitorer DLQ toutes les 10 minutes
@Cron('*/10 * * * *')
async monitorDeadLetters() {
  const dlqStats = await this.rabbitService.getQueueStats([
    'digestion.dlq',
    'transcription.dlq',
    'concordance.dlq'
  ]);

  for (const [queue, stats] of Object.entries(dlqStats)) {
    if (stats.messages > 0) {
      // Alerte si messages en DLQ
      await this.alertService.send({
        severity: 'warning',
        message: `${stats.messages} messages in ${queue}`,
        queue,
        count: stats.messages
      });
    }
  }
}
```

**Rationale :**
- DLQ Ã©vite perte de messages Ã©chouÃ©s
- TTL empÃªche blocage infini (timeout)
- NACK sans requeue â†’ DLQ directement
- Monitoring DLQ = dÃ©tection erreurs systÃ©miques

---

## 12.2 - Retry Logic & Exponential Backoff

**Decision:** Retry avec Fibonacci backoff, max 5 attempts

**Retry Headers (RabbitMQ) :**

```typescript
// Message avec retry count dans headers
interface MessageWithRetry {
  payload: any;
  headers: {
    'x-retry-count': number;
    'x-first-attempt': number;  // Timestamp
    'x-last-attempt': number;
  };
}

// Publisher ajoute headers
await this.rabbitService.publish('digestion.queue', {
  captureId: 'c123',
  userId: 'u456',
}, {
  headers: {
    'x-retry-count': 0,
    'x-first-attempt': Date.now(),
    'x-last-attempt': Date.now(),
  }
});
```

**Consumer avec retry logic :**

```typescript
@Injectable()
class DigestionConsumer {
  private readonly MAX_RETRIES = 5;
  private readonly FIBONACCI_DELAYS = [1, 1, 2, 3, 5, 8];  // Secondes

  async handleDigestion(msg: MessageWithRetry, context: RabbitContext) {
    const channel = context.getChannelRef();
    const originalMsg = context.getMessage();
    const retryCount = msg.headers['x-retry-count'] || 0;

    try {
      await this.digestionService.process(msg.payload);
      channel.ack(originalMsg);

    } catch (error) {
      // VÃ©rifier si erreur retryable
      const isRetryable = this.isRetryableError(error);

      if (!isRetryable || retryCount >= this.MAX_RETRIES) {
        // Non retryable ou max retries â†’ DLQ
        this.logger.error('Max retries reached or non-retryable', { msg, error });
        channel.nack(originalMsg, false, false);  // â†’ DLQ
        return;
      }

      // Retry avec backoff
      const delaySeconds = this.FIBONACCI_DELAYS[retryCount];

      // Re-publier avec delay
      await this.retryWithDelay(msg, retryCount + 1, delaySeconds);

      // ACK message original (sera re-traitÃ© via republication)
      channel.ack(originalMsg);
    }
  }

  private async retryWithDelay(
    msg: MessageWithRetry,
    newRetryCount: number,
    delaySeconds: number
  ) {
    await this.rabbitService.publish(
      'digestion.queue',
      msg.payload,
      {
        headers: {
          'x-retry-count': newRetryCount,
          'x-first-attempt': msg.headers['x-first-attempt'],
          'x-last-attempt': Date.now(),
        },
        // Delayed message exchange plugin
        delay: delaySeconds * 1000,
      }
    );
  }

  private isRetryableError(error: Error): boolean {
    // Erreurs temporaires = retryable
    const retryableErrors = [
      'ECONNREFUSED',     // LLM API down
      'ETIMEDOUT',        // Timeout rÃ©seau
      'ENOTFOUND',        // DNS temporaire
      '429',              // Rate limit LLM
      '503',              // Service unavailable
    ];

    return retryableErrors.some(code =>
      error.message.includes(code) || error.name.includes(code)
    );
  }
}
```

**RabbitMQ Delayed Message Exchange :**

```bash
# Installation plugin
rabbitmq-plugins enable rabbitmq_delayed_message_exchange

# Configuration exchange
{
  "name": "delayed_exchange",
  "type": "x-delayed-message",
  "durable": true,
  "arguments": {
    "x-delayed-type": "direct"
  }
}
```

**Rationale :**
- Fibonacci backoff : progression douce (1s, 1s, 2s, 3s, 5s, 8s)
- Max 5 retries : Ã©vite boucle infinie
- Erreurs retryables vs permanentes : stratÃ©gie diffÃ©renciÃ©e
- Delayed exchange : Ã©vite polling (natif RabbitMQ)

---

## 12.3 - Queue Prioritization

**Decision:** Queues sÃ©parÃ©es avec consommateurs prioritaires

**Architecture multi-queues :**

```typescript
// Queues par prioritÃ© mÃ©tier
const QUEUES = {
  // CRITICAL : impact user immÃ©diat
  transcription: {
    name: 'transcription.queue',
    priority: 'critical',
    consumers: 3,  // 3 workers dÃ©diÃ©s
  },

  // HIGH : expÃ©rience user
  digestion: {
    name: 'digestion.queue',
    priority: 'high',
    consumers: 2,
  },

  // MEDIUM : background
  concordance: {
    name: 'concordance.queue',
    priority: 'medium',
    consumers: 1,
  },

  // LOW : batch
  analytics: {
    name: 'analytics.queue',
    priority: 'low',
    consumers: 1,
  },
};
```

**Consumer avec scaling dynamique :**

```typescript
// NestJS worker scalable
@Module({
  imports: [
    RabbitMQModule.forRoot({
      exchanges: [{ name: 'pensine', type: 'topic' }],
      uri: process.env.RABBITMQ_URI,
      connectionInitOptions: { wait: false },
    }),
  ],
})
class WorkersModule implements OnModuleInit {
  constructor(private rabbitService: AmqpConnection) {}

  onModuleInit() {
    // Spawn consumers selon config
    for (const [name, config] of Object.entries(QUEUES)) {
      for (let i = 0; i < config.consumers; i++) {
        this.spawnConsumer(name, i);
      }
    }
  }

  private spawnConsumer(queueName: string, workerId: number) {
    this.logger.log(`Spawning consumer ${queueName}:${workerId}`);
    // Consumer s'enregistre automatiquement via @RabbitSubscribe
  }
}
```

**Metrics & Auto-scaling (Post-MVP) :**

```typescript
// Monitorer queue depth
@Cron('*/1 * * * *')  // Toutes les minutes
async monitorQueueDepth() {
  const stats = await this.rabbitService.getQueueStats('digestion.queue');

  if (stats.messages > 100) {
    // Queue saturÃ©e â†’ augmenter consumers
    await this.scalingService.scaleUp('digestion', targetConsumers: 4);
  }

  if (stats.messages < 10 && stats.consumers > 2) {
    // Queue vide â†’ rÃ©duire consumers
    await this.scalingService.scaleDown('digestion', targetConsumers: 2);
  }
}
```

**Rationale :**
- Queues sÃ©parÃ©es : isolation pannes (transcription down â‰  digestion bloquÃ©e)
- Consumers dÃ©diÃ©s : garantie traitement prioritaire
- Scaling par queue : optimisation ressources
- MVP : consumers fixes, Post-MVP : auto-scaling

---

## 12.4 - Monitoring & Alerting

**Decision:** MÃ©triques RabbitMQ + alertes proactives

**MÃ©triques RabbitMQ Ã  tracker :**

```typescript
interface QueueMetrics {
  // Volume
  messages: number;           // Messages en attente
  messagesReady: number;      // PrÃªts Ã  consommer
  messagesUnacked: number;    // En cours de traitement

  // Performance
  publishRate: number;        // Msgs/sec publiÃ©s
  consumeRate: number;        // Msgs/sec consommÃ©s
  ackRate: number;            // Msgs/sec acknowledgÃ©s

  // Consumers
  consumers: number;          // Consumers actifs
  consumerUtilisation: number; // % utilisation

  // DurÃ©e
  avgProcessingTime: number;  // Temps moyen traitement
}
```

**Collecte mÃ©triques (Prometheus) :**

```typescript
// NestJS Prometheus exporter
@Injectable()
class RabbitMetricsCollector {
  private readonly gauges = {
    queueDepth: new Gauge({
      name: 'rabbitmq_queue_messages',
      help: 'Messages in queue',
      labelNames: ['queue'],
    }),
    consumers: new Gauge({
      name: 'rabbitmq_queue_consumers',
      help: 'Active consumers',
      labelNames: ['queue'],
    }),
  };

  @Cron('*/30 * * * * *')  // Toutes les 30s
  async collectMetrics() {
    for (const queueName of Object.keys(QUEUES)) {
      const stats = await this.rabbitService.getQueueStats(queueName);

      this.gauges.queueDepth.set({ queue: queueName }, stats.messages);
      this.gauges.consumers.set({ queue: queueName }, stats.consumers);
    }
  }
}
```

**Alertes (critÃ¨res) :**

```typescript
const ALERTS = {
  queueSaturated: {
    condition: 'queue_depth > 500',
    severity: 'warning',
    message: 'Queue saturÃ©e, scaling nÃ©cessaire',
  },

  consumerDown: {
    condition: 'consumers == 0 && queue_depth > 0',
    severity: 'critical',
    message: 'Aucun consumer actif',
  },

  dlqNotEmpty: {
    condition: 'dlq_depth > 0',
    severity: 'warning',
    message: 'Messages en DLQ nÃ©cessitent investigation',
  },

  slowProcessing: {
    condition: 'avg_processing_time > 60000',  // 60s
    severity: 'warning',
    message: 'Traitement lent dÃ©tectÃ©',
  },
};
```

**Dashboard Grafana (KPIs) :**

```
ğŸ“Š RabbitMQ Dashboard

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Queue Depth (real-time)                 â”‚
â”‚ â–‚â–ƒâ–…â–‡â–ˆâ–‡â–…â–ƒâ–‚ Digestion: 23 msgs           â”‚
â”‚ â–â–â–‚â–ƒâ–‚â–â–â–â– Transcription: 5 msgs        â”‚
â”‚ â–â–â–â–â–â–â–â–â– Concordance: 0 msgs          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Throughput (msgs/min)                   â”‚
â”‚ Published: 120 msg/min                  â”‚
â”‚ Consumed: 115 msg/min                   â”‚
â”‚ DLQ: 2 msg/min âš ï¸                      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Processing Time (avg)                   â”‚
â”‚ Digestion: 12.3s                        â”‚
â”‚ Transcription: 45s                      â”‚
â”‚ Concordance: 3.2s                       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Rationale :**
- Prometheus : mÃ©triques time-series standard
- Grafana : visualisation temps rÃ©el
- Alertes proactives : dÃ©tection avant incident
- KPIs mÃ©tier : digestion < 30s, transcription < 2x durÃ©e

---

## ConsÃ©quences Globales ADR-012

**BÃ©nÃ©fices:**
- RÃ©silience : DLQ + retry Ã©vitent perte messages
- Performance : queues prioritaires + scaling
- ObservabilitÃ© : mÃ©triques + alertes proactives
- Maintenance : isolation pannes par queue
- CoÃ»t : RabbitMQ lÃ©ger (< 512 MB RAM pour MVP)

**Trade-offs acceptÃ©s:**
- ComplexitÃ© infrastructure : RabbitMQ + monitoring
- Overhead rÃ©seau : messages retry
- Latence retry : Fibonacci backoff (max 8s avant DLQ)

**Impact:**
- **Epic 3** : Transcription queue (Story 3.1-3.2)
- **Epic 4** : Digestion queue (Story 4.1-4.3)
- **Epic 5** : Concordance queue (Story 5.1-5.3)
- **Infrastructure** : RabbitMQ + Prometheus + Grafana

---

## Implementation Status

- â³ **Epic 3** : Transcription queue
- â³ **Epic 4** : Digestion queue
- â³ **Epic 5** : Concordance queue
- â³ **Infrastructure** : RabbitMQ setup
- â³ **Post-MVP** : Auto-scaling consumers

---

## References

- RabbitMQ Documentation: https://www.rabbitmq.com/documentation.html
- Dead Letter Queues: https://www.rabbitmq.com/dlx.html
- Delayed Message Plugin: https://github.com/rabbitmq/rabbitmq-delayed-message-exchange
- NestJS RabbitMQ: https://docs.nestjs.com/microservices/rabbitmq
- Prometheus Client: https://github.com/siimon/prom-client

---

## Validation Criteria

ADR considÃ©rÃ© succÃ¨s SI :
- â³ DLQ fonctionne (messages Ã©chouÃ©s rÃ©cupÃ©rables)
- â³ Retry logic fonctionne (max 5 attempts)
- â³ Queues prioritaires respectÃ©es (transcription > digestion > concordance)
- â³ Alertes Grafana opÃ©rationnelles
- â³ 0 perte de messages en production (1 mois monitoring)

**Review Date :** 2026-03 (aprÃ¨s Epic 5)

---

**Participants :**
- yohikofox (Product Owner)
- Winston (Architect)
